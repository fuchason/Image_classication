{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# set Ture during training, False during testing\n",
    "TRAINING = True\n",
    "\n",
    "\n",
    "def identity_block(X_input, kernel_size, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    with tf.name_scope(\"id_block_stage\"+str(stage)):\n",
    "        filter1, filter2, filter3 = filters\n",
    "        X_shortcut = X_input\n",
    "\n",
    "        # First component of main path\n",
    "        x = tf.layers.conv2d(X_input, filter1,\n",
    "                 kernel_size=(1, 1), strides=(1, 1),name=conv_name_base+'2a')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base+'2a', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Second component of main path\n",
    "        x = tf.layers.conv2d(x, filter2, (kernel_size, kernel_size),\n",
    "                                 padding='same', name=conv_name_base+'2b')\n",
    "        # batch_norm2 = tf.layers.batch_normalization(conv2, axis=3, name=bn_name_base+'2b', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Third component of main path\n",
    "        x = tf.layers.conv2d(x, filter3, kernel_size=(1, 1),name=conv_name_base+'2c')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2c', training=TRAINING)\n",
    "\n",
    "        # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "        X_add_shortcut = tf.add(x, X_shortcut)\n",
    "        add_result = tf.nn.relu(X_add_shortcut)\n",
    "\n",
    "    return add_result\n",
    "\n",
    "\n",
    "def convolutional_block(X_input, kernel_size, filters, stage, block, stride = 2):\n",
    "    #change the shape of output so that it can do sum process with shotcut\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    with tf.name_scope(\"conv_block_stage\" + str(stage)):\n",
    "\n",
    "        # Retrieve Filters\n",
    "        filter1, filter2, filter3 = filters\n",
    "\n",
    "        # Save the input value\n",
    "        X_shortcut = X_input\n",
    "\n",
    "        # First component of main path\n",
    "        x = tf.layers.conv2d(X_input, filter1,\n",
    "                                 kernel_size=(1, 1),\n",
    "                                 strides=(stride, stride),\n",
    "                                 name=conv_name_base+'2a')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base+'2a', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Second component of main path\n",
    "        x = tf.layers.conv2d(x, filter2, (kernel_size, kernel_size), name=conv_name_base + '2b',padding='same')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2b', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Third component of main path\n",
    "        x = tf.layers.conv2d(x, filter3, (1, 1), name=conv_name_base + '2c')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2c', training=TRAINING)\n",
    "\n",
    "        # SHORTCUT PATH\n",
    "        X_shortcut = tf.layers.conv2d(X_shortcut, filter3, (1,1),\n",
    "                                      strides=(stride, stride), name=conv_name_base + '1')\n",
    "        X_shortcut = tf.layers.batch_normalization(X_shortcut, axis=3, name=bn_name_base + '1', training=TRAINING)\n",
    "\n",
    "        # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "        X_add_shortcut = tf.add(X_shortcut, x)\n",
    "        add_result = tf.nn.relu(X_add_shortcut)\n",
    "\n",
    "    return add_result\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50_reference(X, classes= 2):\n",
    "#     x = tf.pad(X, tf.constant([[0, 0],[3, 3,], [3, 3], [0, 0]]), \"CONSTANT\")\n",
    "\n",
    "#     assert(x.shape == (x.shape[0], 70, 70, 1))\n",
    "\n",
    "    # stage 1\n",
    "    x = tf.layers.conv2d(X, filters=64, kernel_size=(7, 7), strides=(2, 2), name='conv1')\n",
    "    x = tf.layers.batch_normalization(x, axis=3, name='bn_conv1')\n",
    "    x = tf.nn.relu(x)\n",
    "    # local response normalization\n",
    "    x = tf.nn.lrn(x, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=(3, 3),strides=(2, 2))\n",
    "    \n",
    "\n",
    "\n",
    "    # stage 2\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[64, 64, 256], stage=2, block='a', stride=1)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # stage 3\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[128,128,512],\n",
    "                                            stage=3, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='d')\n",
    "\n",
    "    # stage 4\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[256, 256, 1024], stage=4, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # stage 5\n",
    "    x = convolutional_block(x,kernel_size=3,filters=[512, 512, 2048], stage=5, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    #x = tf.layers.average_pooling2d(x, pool_size=(2, 2), strides=(1,1))\n",
    "    # local response normalization\n",
    "    x = tf.nn.lrn(x, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=(2, 2), strides=(1,1))\n",
    "\n",
    "    flatten = tf.layers.flatten(x, name='flatten')\n",
    "    keep_prob = 0.5\n",
    "    # dropout\n",
    "    drop = tf.nn.dropout(flatten, keep_prob)\n",
    "    dense1 = tf.layers.dense(drop, units=50, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(dense1, units=2, activation=tf.nn.softmax)\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(logits, labels, name):\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits \\\n",
    "            (logits=logits, labels=labels, name='xentropy_per_example')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_loss', loss)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_loss', loss)\n",
    "    return loss\n",
    " \n",
    "def trainning(loss, learning_rate):\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_op = optimizer.minimize(loss, global_step= global_step)\n",
    "    return train_op\n",
    " \n",
    "def evaluation(logits, labels, name):\n",
    "    with tf.variable_scope('accuracy') as scope:\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        correct = tf.cast(correct, tf.float16)\n",
    "        accuracy = tf.reduce_mean(correct)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_accuracy', accuracy)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_accuracy', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def recall_precision(logits, labels, name):\n",
    "    logits = tf.cast(logits, tf.int64)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    predict = tf.arg_max(logits,1)\n",
    "    with tf.variable_scope('recall_precision') as scope:\n",
    "        TP = tf.count_nonzero(predict * labels)\n",
    "        TN = tf.count_nonzero((predict - 1) * (labels - 1))\n",
    "        FN = tf.count_nonzero(predict * (labels - 1))\n",
    "        FP = tf.count_nonzero((predict - 1) * labels)\n",
    "        precision = tf.divide(TP, TP + FP)\n",
    "        recall = tf.divide(TP, TP + FN)\n",
    "        precision = tf.cast(precision, dtype=tf.float64)\n",
    "        recall = tf.cast(recall, dtype=tf.float64)\n",
    "        #f1 = 2 * precision * recall / (precision + recall)\n",
    "        #f1 = tf.cast(f1, dtype=tf.float32)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/train_recall', recall)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/valid_recall', recall)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "def get_files(path_pos,path_neg,label_pos,label_neg):\n",
    "    TC = []\n",
    "    label_TC = []\n",
    "    nonTC = []\n",
    "    label_nonTC = []\n",
    "    # data loader\n",
    "    file_dir_TC=path_pos\n",
    "    file_dir_nonTC=path_neg\n",
    "    for file in os.listdir(file_dir_TC):\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_pos:\n",
    "            TC.append(file_dir_TC + file)\n",
    "            label_TC.append(1)\n",
    "    for file in os.listdir(file_dir_nonTC):\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_neg:\n",
    "            nonTC.append(file_dir_nonTC + file)\n",
    "            label_nonTC.append(0)\n",
    "    print(\"There are %d TC\\nThere are %d nonTC\" % (len(TC), len(nonTC)))\n",
    " \n",
    "    # shuffle\n",
    "    image_list = np.hstack((TC, nonTC))\n",
    "    label_list = np.hstack((label_TC, label_nonTC))\n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()    \n",
    "    np.random.shuffle(temp)\n",
    " \n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    " \n",
    "    return image_list, label_list\n",
    " \n",
    "# img_list,label_list = get_files(file_dir)\n",
    " \n",
    "# batch\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):   \n",
    "    image = tf.cast(image, tf.string)\n",
    "    label = tf.cast(label, tf.int32)\n",
    " \n",
    "    # queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    " \n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    label = input_queue[1]\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=1)\n",
    " \n",
    "    # resize\n",
    "    image = tf.image.resize_images(image, [image_H, image_W], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # image = tf.image.per_image_standardization(image)  \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,  \n",
    "                                              capacity=capacity)\n",
    "  \n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2016816 TC\n",
      "There are 1737956 nonTC\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:187: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-b39e5d5309b2>:32: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From <ipython-input-4-8949b66f2dc2>:60: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "----------training start---------\n",
      "Step 0, train loss = 0.91, train accuracy = 39.06%, train recall = 0.00%, train precision = 0.00%\n",
      "Step 50, train loss = 0.79, train accuracy = 51.56%, train recall = 2.78%, train precision = 100.00%\n",
      "Step 100, train loss = 0.49, train accuracy = 82.81%, train recall = 6.67%, train precision = 100.00%\n",
      "Step 150, train loss = 0.53, train accuracy = 78.12%, train recall = 37.84%, train precision = 93.33%\n",
      "Step 200, train loss = 0.58, train accuracy = 71.88%, train recall = 44.44%, train precision = 88.89%\n",
      "Step 250, train loss = 0.61, train accuracy = 70.31%, train recall = 33.33%, train precision = 86.67%\n",
      "Step 300, train loss = 0.57, train accuracy = 73.44%, train recall = 50.00%, train precision = 78.95%\n",
      "Step 350, train loss = 0.47, train accuracy = 82.81%, train recall = 52.50%, train precision = 91.30%\n",
      "Step 400, train loss = 0.62, train accuracy = 68.75%, train recall = 53.33%, train precision = 76.19%\n",
      "Step 450, train loss = 0.55, train accuracy = 76.56%, train recall = 61.76%, train precision = 84.00%\n",
      "Step 500, train loss = 0.53, train accuracy = 76.56%, train recall = 50.00%, train precision = 78.95%\n",
      "Step 550, train loss = 0.55, train accuracy = 76.56%, train recall = 61.76%, train precision = 87.50%\n",
      "Step 600, train loss = 0.45, train accuracy = 85.94%, train recall = 73.68%, train precision = 96.55%\n",
      "Step 650, train loss = 0.60, train accuracy = 71.88%, train recall = 73.53%, train precision = 80.65%\n",
      "Step 700, train loss = 0.61, train accuracy = 70.31%, train recall = 60.00%, train precision = 84.00%\n",
      "Step 750, train loss = 0.51, train accuracy = 79.69%, train recall = 65.62%, train precision = 87.50%\n",
      "Step 800, train loss = 0.53, train accuracy = 78.12%, train recall = 75.86%, train precision = 81.48%\n",
      "Step 850, train loss = 0.58, train accuracy = 73.44%, train recall = 77.27%, train precision = 62.96%\n",
      "Step 900, train loss = 0.63, train accuracy = 67.19%, train recall = 61.11%, train precision = 88.00%\n",
      "Step 950, train loss = 0.46, train accuracy = 84.38%, train recall = 70.97%, train precision = 88.00%\n",
      "Step 1000, train loss = 0.49, train accuracy = 82.81%, train recall = 64.71%, train precision = 88.00%\n",
      "Step 1050, train loss = 0.49, train accuracy = 81.25%, train recall = 68.75%, train precision = 88.00%\n",
      "Step 1100, train loss = 0.49, train accuracy = 81.25%, train recall = 57.89%, train precision = 91.67%\n",
      "Step 1150, train loss = 0.56, train accuracy = 75.00%, train recall = 43.75%, train precision = 73.68%\n",
      "Step 1200, train loss = 0.46, train accuracy = 85.94%, train recall = 64.29%, train precision = 85.71%\n",
      "Step 1250, train loss = 0.43, train accuracy = 89.06%, train recall = 72.73%, train precision = 100.00%\n",
      "Step 1300, train loss = 0.50, train accuracy = 81.25%, train recall = 40.00%, train precision = 94.12%\n",
      "Step 1350, train loss = 0.53, train accuracy = 76.56%, train recall = 73.08%, train precision = 76.00%\n",
      "Step 1400, train loss = 0.47, train accuracy = 84.38%, train recall = 64.71%, train precision = 88.00%\n",
      "Step 1450, train loss = 0.53, train accuracy = 76.56%, train recall = 64.71%, train precision = 84.62%\n",
      "Step 1500, train loss = 0.52, train accuracy = 78.12%, train recall = 52.94%, train precision = 94.74%\n",
      "Step 1550, train loss = 0.48, train accuracy = 82.81%, train recall = 52.94%, train precision = 94.74%\n",
      "Step 1600, train loss = 0.51, train accuracy = 79.69%, train recall = 55.17%, train precision = 88.89%\n",
      "Step 1650, train loss = 0.57, train accuracy = 68.75%, train recall = 51.43%, train precision = 85.71%\n",
      "Step 1700, train loss = 0.49, train accuracy = 76.56%, train recall = 51.52%, train precision = 85.00%\n",
      "Step 1750, train loss = 0.56, train accuracy = 73.44%, train recall = 48.48%, train precision = 84.21%\n",
      "Step 1800, train loss = 0.48, train accuracy = 84.38%, train recall = 57.89%, train precision = 95.65%\n",
      "Step 1850, train loss = 0.47, train accuracy = 87.50%, train recall = 41.18%, train precision = 87.50%\n",
      "Step 1900, train loss = 0.50, train accuracy = 82.81%, train recall = 42.86%, train precision = 100.00%\n",
      "Step 1950, train loss = 0.54, train accuracy = 75.00%, train recall = 48.65%, train precision = 100.00%\n",
      "Step 2000, train loss = 0.51, train accuracy = 81.25%, train recall = 48.78%, train precision = 90.91%\n",
      "Step 2050, train loss = 0.49, train accuracy = 79.69%, train recall = 51.28%, train precision = 100.00%\n",
      "Step 2100, train loss = 0.47, train accuracy = 82.81%, train recall = 60.00%, train precision = 94.74%\n",
      "Step 2150, train loss = 0.49, train accuracy = 81.25%, train recall = 55.88%, train precision = 100.00%\n",
      "Step 2200, train loss = 0.49, train accuracy = 79.69%, train recall = 47.06%, train precision = 84.21%\n",
      "Step 2250, train loss = 0.47, train accuracy = 84.38%, train recall = 63.89%, train precision = 100.00%\n",
      "Step 2300, train loss = 0.50, train accuracy = 81.25%, train recall = 62.50%, train precision = 95.24%\n",
      "Step 2350, train loss = 0.44, train accuracy = 87.50%, train recall = 39.47%, train precision = 88.24%\n",
      "Step 2400, train loss = 0.45, train accuracy = 85.94%, train recall = 65.62%, train precision = 100.00%\n",
      "Step 2450, train loss = 0.44, train accuracy = 85.94%, train recall = 53.49%, train precision = 100.00%\n",
      "Step 2500, train loss = 0.42, train accuracy = 89.06%, train recall = 44.44%, train precision = 100.00%\n",
      "Step 2550, train loss = 0.43, train accuracy = 87.50%, train recall = 48.65%, train precision = 100.00%\n",
      "Step 2600, train loss = 0.48, train accuracy = 82.81%, train recall = 45.45%, train precision = 83.33%\n",
      "Step 2650, train loss = 0.47, train accuracy = 82.81%, train recall = 45.95%, train precision = 94.44%\n",
      "Step 2700, train loss = 0.43, train accuracy = 87.50%, train recall = 50.00%, train precision = 100.00%\n",
      "Step 2750, train loss = 0.49, train accuracy = 79.69%, train recall = 48.65%, train precision = 94.74%\n",
      "Step 2800, train loss = 0.52, train accuracy = 75.00%, train recall = 59.38%, train precision = 95.00%\n",
      "Step 2850, train loss = 0.51, train accuracy = 79.69%, train recall = 51.35%, train precision = 95.00%\n",
      "Step 2900, train loss = 0.59, train accuracy = 73.44%, train recall = 51.61%, train precision = 88.89%\n",
      "Step 2950, train loss = 0.52, train accuracy = 76.56%, train recall = 46.15%, train precision = 90.00%\n",
      "Step 3000, train loss = 0.48, train accuracy = 81.25%, train recall = 57.14%, train precision = 95.24%\n",
      "Step 3050, train loss = 0.56, train accuracy = 75.00%, train recall = 51.52%, train precision = 80.95%\n",
      "Step 3100, train loss = 0.49, train accuracy = 81.25%, train recall = 52.27%, train precision = 100.00%\n",
      "Step 3150, train loss = 0.46, train accuracy = 84.38%, train recall = 46.34%, train precision = 100.00%\n",
      "Step 3200, train loss = 0.49, train accuracy = 82.81%, train recall = 61.11%, train precision = 95.65%\n",
      "Step 3250, train loss = 0.48, train accuracy = 81.25%, train recall = 52.63%, train precision = 100.00%\n",
      "Step 3300, train loss = 0.47, train accuracy = 82.81%, train recall = 67.57%, train precision = 96.15%\n",
      "Step 3350, train loss = 0.45, train accuracy = 81.25%, train recall = 66.67%, train precision = 92.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3400, train loss = 0.51, train accuracy = 79.69%, train recall = 72.00%, train precision = 85.71%\n",
      "Step 3450, train loss = 0.48, train accuracy = 81.25%, train recall = 63.89%, train precision = 92.00%\n",
      "Step 3500, train loss = 0.50, train accuracy = 81.25%, train recall = 56.76%, train precision = 95.45%\n",
      "Step 3550, train loss = 0.49, train accuracy = 82.81%, train recall = 47.62%, train precision = 95.24%\n",
      "Step 3600, train loss = 0.45, train accuracy = 87.50%, train recall = 68.57%, train precision = 96.00%\n",
      "Step 3650, train loss = 0.49, train accuracy = 81.25%, train recall = 68.57%, train precision = 85.71%\n",
      "Step 3700, train loss = 0.47, train accuracy = 82.81%, train recall = 62.16%, train precision = 88.46%\n",
      "Step 3750, train loss = 0.42, train accuracy = 90.62%, train recall = 68.57%, train precision = 92.31%\n",
      "Step 3800, train loss = 0.44, train accuracy = 87.50%, train recall = 57.58%, train precision = 90.48%\n",
      "Step 3850, train loss = 0.54, train accuracy = 78.12%, train recall = 63.33%, train precision = 86.36%\n",
      "Step 3900, train loss = 0.42, train accuracy = 87.50%, train recall = 78.57%, train precision = 100.00%\n",
      "Step 3950, train loss = 0.46, train accuracy = 84.38%, train recall = 57.14%, train precision = 100.00%\n",
      "Step 4000, train loss = 0.52, train accuracy = 76.56%, train recall = 50.00%, train precision = 94.74%\n",
      "Step 4050, train loss = 0.45, train accuracy = 82.81%, train recall = 66.67%, train precision = 84.21%\n",
      "Step 4100, train loss = 0.51, train accuracy = 79.69%, train recall = 50.00%, train precision = 95.45%\n",
      "Step 4150, train loss = 0.52, train accuracy = 76.56%, train recall = 65.52%, train precision = 100.00%\n",
      "Step 4200, train loss = 0.48, train accuracy = 85.94%, train recall = 60.71%, train precision = 89.47%\n",
      "Step 4250, train loss = 0.40, train accuracy = 90.62%, train recall = 60.61%, train precision = 100.00%\n",
      "Step 4300, train loss = 0.46, train accuracy = 79.69%, train recall = 70.97%, train precision = 100.00%\n",
      "Step 4350, train loss = 0.49, train accuracy = 81.25%, train recall = 63.64%, train precision = 95.45%\n",
      "Step 4400, train loss = 0.52, train accuracy = 73.44%, train recall = 54.55%, train precision = 100.00%\n",
      "Step 4450, train loss = 0.50, train accuracy = 81.25%, train recall = 47.22%, train precision = 89.47%\n",
      "Step 4500, train loss = 0.47, train accuracy = 81.25%, train recall = 67.86%, train precision = 86.36%\n",
      "Step 4550, train loss = 0.42, train accuracy = 90.62%, train recall = 71.43%, train precision = 100.00%\n",
      "Step 4600, train loss = 0.42, train accuracy = 90.62%, train recall = 52.63%, train precision = 95.24%\n",
      "Step 4650, train loss = 0.49, train accuracy = 82.81%, train recall = 51.35%, train precision = 86.36%\n",
      "Step 4700, train loss = 0.41, train accuracy = 89.06%, train recall = 58.33%, train precision = 100.00%\n",
      "Step 4750, train loss = 0.42, train accuracy = 89.06%, train recall = 69.44%, train precision = 100.00%\n",
      "Step 4800, train loss = 0.43, train accuracy = 89.06%, train recall = 55.26%, train precision = 100.00%\n",
      "Step 4850, train loss = 0.45, train accuracy = 84.38%, train recall = 63.16%, train precision = 100.00%\n",
      "Step 4900, train loss = 0.44, train accuracy = 84.38%, train recall = 65.71%, train precision = 92.00%\n",
      "Step 4950, train loss = 0.40, train accuracy = 90.62%, train recall = 52.63%, train precision = 100.00%\n",
      "Step 5000, train loss = 0.56, train accuracy = 75.00%, train recall = 62.50%, train precision = 95.24%\n",
      "Step 5050, train loss = 0.45, train accuracy = 85.94%, train recall = 67.86%, train precision = 95.00%\n",
      "Step 5100, train loss = 0.42, train accuracy = 90.62%, train recall = 70.59%, train precision = 100.00%\n",
      "Step 5150, train loss = 0.53, train accuracy = 76.56%, train recall = 59.46%, train precision = 100.00%\n",
      "Step 5200, train loss = 0.54, train accuracy = 76.56%, train recall = 62.07%, train precision = 90.00%\n",
      "Step 5250, train loss = 0.47, train accuracy = 84.38%, train recall = 54.29%, train precision = 100.00%\n",
      "Step 5300, train loss = 0.41, train accuracy = 85.94%, train recall = 67.65%, train precision = 100.00%\n",
      "Step 5350, train loss = 0.56, train accuracy = 75.00%, train recall = 47.06%, train precision = 76.19%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "N_CLASSES = 2 \n",
    "IMG_W = 64  # resize\n",
    "IMG_H = 64\n",
    "BATCH_SIZE = 64\n",
    "CAPACITY = 2000\n",
    "MAX_STEP = 5000000 \n",
    "learning_rate = 0.0001 \n",
    " \n",
    "train_dir = './train_resnet/'\n",
    "logs_train_dir = './train_resnet/'\n",
    "\n",
    "file_dir_TC='/home/ubuntu/data/TC/'\n",
    "file_dir_nonTC='/home/ubuntu/data/nonTC/'\n",
    "# file_dir_valTC='/home/ubuntu/data/valTC/'\n",
    "# file_dir_valnonTC='/home/ubuntu/data/valnonTC/'\n",
    "\n",
    "train, train_label = get_files(file_dir_TC,file_dir_nonTC,'TC','nonTC')\n",
    "# valid, valid_label = get_files(file_dir_valTC,file_dir_valnonTC,'valTC','valnonTC')\n",
    "train_batch,train_label_batch=get_batch(train,\n",
    "                                train_label,\n",
    "                                IMG_W,\n",
    "                                IMG_H,\n",
    "                                BATCH_SIZE,\n",
    "                                CAPACITY)\n",
    "\n",
    "# valid_batch,valid_label_batch=get_batch(valid,\n",
    "#                                 valid_label,\n",
    "#                                 IMG_W,\n",
    "#                                 IMG_H,\n",
    "#                                 BATCH_SIZE,\n",
    "#                                 CAPACITY)\n",
    "# x = tf.placeholder(tf.float32, [BATCH_SIZE,IMG_W,IMG_H,1])\n",
    "# y = tf.placeholder(tf.float32, [BATCH_SIZE])\n",
    "# y = tf.cast(y,tf.int64)\n",
    "\n",
    "train_logits = ResNet50_reference(train_batch)\n",
    "train_loss = losses(train_logits, train_label_batch, 'train')\n",
    "# valid_loss = losses(train_logits, y, 'valid')\n",
    "train_op = trainning(train_loss, learning_rate)\n",
    "train__acc = evaluation(train_logits, train_label_batch, 'train')\n",
    "# valid__acc = evaluation(train_logits, y, 'valid')\n",
    "train_recall, train_precision = recall_precision(train_logits, train_label_batch, 'train')\n",
    "# val_recall, val_precision = recall_precision(train_logits, y, 'valid')\n",
    "summary_op = tf.summary.merge_all() \n",
    " \n",
    "sess = tf.Session()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(logs_train_dir, sess.graph)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    " \n",
    "try:\n",
    "    print('----------training start---------')\n",
    "    for step in np.arange(MAX_STEP):\n",
    "        \n",
    "        if coord.should_stop():\n",
    "                break\n",
    "       \n",
    "        _, tra_loss, tra_acc, tra_recall, tra_precision= sess.run([train_op, train_loss, train__acc, train_recall, train_precision])\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print('Step %d, train loss = %.2f, train accuracy = %.2f%%, train recall = %.2f%%, train precision = %.2f%%' %(step, tra_loss, tra_acc*100.0, tra_recall*100.0, tra_precision*100.0))\n",
    "            \n",
    "#         if step % 200 == 0:    \n",
    "#             val_loss, val_acc, cal_recall, val_precision = sess.run([valid_loss, valid__acc, val_recall, val_precision], feed_dict={x:valid_batch,y:valid_label_batch})\n",
    "#             print('Step %d, valid loss = %.2f, valid accuracy = %.2f%%, valid recall = %.2f%%, valid precision = %.2f%%' %(step, val_loss, val_acc*100.0, val_recall*100.0, val_precision*100.0))\n",
    "            summary_str = sess.run(summary_op)\n",
    "            train_writer.add_summary(summary_str, step)\n",
    "      \n",
    "        if step % 2000 == 0 or (step + 1) == MAX_STEP:\n",
    "            checkpoint_path = os.path.join(logs_train_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training -- epoch limit reached')\n",
    "\n",
    "finally:\n",
    "    coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
