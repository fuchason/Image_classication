{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "# set Ture during training, False during testing\n",
    "TRAINING = True\n",
    "\n",
    "def gaussian_mask(u, s, d, R, C):\n",
    "    \"\"\"\n",
    "    :param u: tf.Tensor, centre of the first Gaussian.\n",
    "    :param s: tf.Tensor, standard deviation of Gaussians.\n",
    "    :param d: tf.Tensor, shift between Gaussian centres.\n",
    "    :param R: int, number of rows in the mask, there is one Gaussian per row.\n",
    "    :param C: int, number of columns in the mask.\n",
    "    \"\"\"\n",
    "    # indices to create centres\n",
    "    R = tf.to_float(tf.reshape(tf.range(R), (1, 1, R)))\n",
    "    print('R',np.shape(R))\n",
    "    C = tf.to_float(tf.reshape(tf.range(C), (1, C, 1)))\n",
    "    print('C',np.shape(C))\n",
    "    centres = u[np.newaxis, :, np.newaxis] + R * d\n",
    "    print('centres',np.shape(centres))\n",
    "    column_centres = C - centres\n",
    "    print('column_centres',np.shape(column_centres))\n",
    "    mask = tf.exp(-.5 * tf.square(column_centres / s))\n",
    "    print('mask',np.shape(mask))\n",
    "    # we add eps for numerical stability\n",
    "    normalised_mask = mask / (tf.reduce_sum(mask, 1, keep_dims=True) + 1e-8)\n",
    "    print('normalised_mask',np.shape(normalised_mask))\n",
    "    batch_normalised_mask=[]\n",
    "    for _ in range(64):\n",
    "        batch_normalised_mask.append(normalised_mask[0])\n",
    "    return batch_normalised_mask\n",
    "\n",
    "def gaussian_glimpse(img_tensor, transform_params, crop_size):\n",
    "    \"\"\"\n",
    "    :param img_tensor: tf.Tensor of size (batch_size, Height, Width, channels)\n",
    "    :param transform_params: tf.Tensor of size (batch_size, 6), where params are  (mean_y, std_y, d_y, mean_x, std_x, d_x) specified in pixels.\n",
    "    :param crop_size): tuple of 2 ints, size of the resulting crop\n",
    "    \"\"\"\n",
    "    # parse arguments\n",
    "    h, w = crop_size\n",
    "    H, W = img_tensor.shape.as_list()[1:3]\n",
    "    split_ax = transform_params.shape.ndims -1\n",
    "    uy, sy, dy, ux, sx, dx = tf.split(transform_params, 6, split_ax)\n",
    "    # create Gaussian masks, one for each axis\n",
    "    Ay = gaussian_mask(uy, sy, dy, h, H)\n",
    "    print('Ay',np.shape(Ay))\n",
    "    Ax = gaussian_mask(ux, sx, dx, w, W)\n",
    "    print('Ax',np.shape(Ax))\n",
    "    # extract glimpse\n",
    "    glimpse = tf.matmul(tf.matmul(img_tensor,Ay, adjoint_a=True), Ax)\n",
    "    return glimpse\n",
    "\n",
    "def spatial_transformer(img_tensor, transform_params, crop_size):\n",
    "    \"\"\"\n",
    "    :param img_tensor: tf.Tensor of size (batch_size, Height, Width, channels)\n",
    "    :param transform_params: tf.Tensor of size (batch_size, 4), where params are  (scale_y, shift_y, scale_x, shift_x)\n",
    "    :param crop_size): tuple of 2 ints, size of the resulting crop\n",
    "    \"\"\"\n",
    "    constraints = snt.AffineWarpConstraints.no_shear_2d()\n",
    "    print('constraints',np.shape(constraints))\n",
    "    img_size = img_tensor.shape.as_list()[1:]\n",
    "    print('img_size',img_size)\n",
    "    warper = snt.AffineGridWarper(img_size, crop_size, constraints)\n",
    "    grid_coords = warper(transform_params)\n",
    "    glimpse = tf.contrib.resampler.resampler(img_tensor[..., tf.newaxis], grid_coords)\n",
    "    return glimpse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X_input, kernel_size, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    with tf.name_scope(\"id_block_stage\"+str(stage)):\n",
    "        filter1, filter2, filter3 = filters\n",
    "        X_shortcut = X_input\n",
    "\n",
    "        # First component of main path\n",
    "        x = tf.layers.conv2d(X_input, filter1,\n",
    "                 kernel_size=(1, 1), strides=(1, 1),name=conv_name_base+'2a')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base+'2a', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Second component of main path\n",
    "        x = tf.layers.conv2d(x, filter2, (kernel_size, kernel_size),\n",
    "                                 padding='same', name=conv_name_base+'2b')\n",
    "        # batch_norm2 = tf.layers.batch_normalization(conv2, axis=3, name=bn_name_base+'2b', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Third component of main path\n",
    "        x = tf.layers.conv2d(x, filter3, kernel_size=(1, 1),name=conv_name_base+'2c')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2c', training=TRAINING)\n",
    "\n",
    "        # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "        X_add_shortcut = tf.add(x, X_shortcut)\n",
    "        add_result = tf.nn.relu(X_add_shortcut)\n",
    "\n",
    "    return add_result\n",
    "\n",
    "\n",
    "def convolutional_block(X_input, kernel_size, filters, stage, block, stride = 2):\n",
    "    #change the shape of output so that it can do sum process with shotcut\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    with tf.name_scope(\"conv_block_stage\" + str(stage)):\n",
    "\n",
    "        # Retrieve Filters\n",
    "        filter1, filter2, filter3 = filters\n",
    "\n",
    "        # Save the input value\n",
    "        X_shortcut = X_input\n",
    "\n",
    "        # First component of main path\n",
    "        x = tf.layers.conv2d(X_input, filter1,\n",
    "                                 kernel_size=(1, 1),\n",
    "                                 strides=(stride, stride),\n",
    "                                 name=conv_name_base+'2a')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base+'2a', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Second component of main path\n",
    "        x = tf.layers.conv2d(x, filter2, (kernel_size, kernel_size), name=conv_name_base + '2b',padding='same')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2b', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Third component of main path\n",
    "        x = tf.layers.conv2d(x, filter3, (1, 1), name=conv_name_base + '2c')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2c', training=TRAINING)\n",
    "\n",
    "        # SHORTCUT PATH\n",
    "        X_shortcut = tf.layers.conv2d(X_shortcut, filter3, (1,1),\n",
    "                                      strides=(stride, stride), name=conv_name_base + '1')\n",
    "        X_shortcut = tf.layers.batch_normalization(X_shortcut, axis=3, name=bn_name_base + '1', training=TRAINING)\n",
    "\n",
    "        # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "        X_add_shortcut = tf.add(X_shortcut, x)\n",
    "        add_result = tf.nn.relu(X_add_shortcut)\n",
    "\n",
    "    return add_result\n",
    "\n",
    "\n",
    "\n",
    "after_attention = []\n",
    "def ResNet50_reference(X, classes= 2):\n",
    "#     x = tf.pad(X, tf.constant([[0, 0],[3, 3,], [3, 3], [0, 0]]), \"CONSTANT\")\n",
    "\n",
    "#     assert(x.shape == (x.shape[0], 70, 70, 1))\n",
    "    global after_attention\n",
    "    \n",
    "    print('X',np.shape(X))\n",
    "    img_x, img_y=np.shape(X)[1:]\n",
    "    glimpse_size = 64,64\n",
    "#     u = 2.\n",
    "#     s = .5\n",
    "#     d = 1.\n",
    "#     u, s, d = (np.asarray([i]) for i in (u, s, d))\n",
    "#     para=[]\n",
    "#     for _ in range(64):\n",
    "#         para.append([2.,.5,1.,2.,.5,1.])\n",
    "#     print(np.shape(para))\n",
    "#     gaussian_att_params = tf.cast(tf.reshape(para, [64,6]),tf.float32)\n",
    "#     gaussian_att_params = np.array(para)\n",
    "   \n",
    "    transform = [.4, -.1, .4, -.1]\n",
    "    para_spt=[]\n",
    "    for _ in range(1024):\n",
    "        para_spt.append([.4, -.1, .4, -.1])\n",
    "    print('para_spt',np.shape(para_spt)) \n",
    "    para_spt=tf.cast(para_spt,tf.float32)\n",
    "    \n",
    "    # attention\n",
    "#     x = spatial_transformer(tf.reshape(X,[1024,img_x,img_y]), para_spt, glimpse_size)\n",
    "#     after_attention.append(x)\n",
    "    X=tf.reshape(X,[1024,img_x,img_y,1])\n",
    "    # stage 1\n",
    "    x = tf.layers.conv2d(X, filters=64, kernel_size=(3, 3), strides=(2, 2), name='conv1')\n",
    "    x = tf.layers.batch_normalization(x, axis=3, name='bn_conv1')\n",
    "    x = tf.nn.relu(x)\n",
    "    # local response normalization\n",
    "    x = tf.nn.lrn(x, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=(3, 3),strides=(2, 2))\n",
    "    \n",
    "#      x = convolutional_block(x, kernel_size=3, filters=[64, 64, 64], stage=2, block='attention_a', stride=1)\n",
    "#     x = identity_block(x, 3, [64, 64, 64], stage=0, block='attention_b')\n",
    "#     x = identity_block(x, 3, [64, 64, 64], stage=0, block='attention_c')\n",
    "#     x = gaussian_glimpse(x, gaussian_att_params, glimpse_size)\n",
    "    \n",
    "    # stage 2\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[64, 64, 256], stage=2, block='a', stride=1)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    \n",
    "#     # attention\n",
    "#     x = convolutional_block(x, kernel_size=3, filters=[64, 64, 64], stage=2, block='attention_a', stride=1)\n",
    "#     x = identity_block(x, 3, [64, 64, 64], stage=0, block='attention_b')\n",
    "#     x = identity_block(x, 3, [64, 64, 64], stage=0, block='attention_c')\n",
    "#     x = gaussian_glimpse(x, gaussian_att_params, glimpse_size)\n",
    "\n",
    "    # stage 3\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[128,128,512],\n",
    "                                            stage=3, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='d')\n",
    "\n",
    "    # stage 4\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[256, 256, 1024], stage=4, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # stage 5\n",
    "    x = convolutional_block(x,kernel_size=3,filters=[512, 512, 2048], stage=5, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    #x = tf.layers.average_pooling2d(x, pool_size=(2, 2), strides=(1,1))\n",
    "    # local response normalization\n",
    "    x = tf.nn.lrn(x, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=(2, 2), strides=(1,1))\n",
    "\n",
    "    flatten = tf.layers.flatten(x, name='flatten')\n",
    "    keep_prob = 1\n",
    "    # dropout\n",
    "    drop = tf.nn.dropout(flatten, keep_prob)\n",
    "    dense1 = tf.layers.dense(drop, units=50, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(dense1, units=2, activation=tf.nn.softmax)\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(logits, labels, name):\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits \\\n",
    "            (logits=logits, labels=labels, name='xentropy_per_example')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_loss', loss)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_loss', loss)\n",
    "    return loss\n",
    " \n",
    "def trainning(loss, learning_rate):\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_op = optimizer.minimize(loss, global_step= global_step)\n",
    "    return train_op\n",
    " \n",
    "def evaluation(logits, labels, name):\n",
    "    with tf.variable_scope('accuracy') as scope:\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        correct = tf.cast(correct, tf.float16)\n",
    "        accuracy = tf.reduce_mean(correct)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_accuracy', accuracy)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_accuracy', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def recall_precision(logits, labels, name):\n",
    "    logits = tf.cast(logits, tf.int64)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    predict = tf.arg_max(logits,1)\n",
    "    with tf.variable_scope('recall_precision') as scope:\n",
    "        TP = tf.count_nonzero(predict * labels)\n",
    "        TN = tf.count_nonzero((predict - 1) * (labels - 1))\n",
    "        FN = tf.count_nonzero(predict * (labels - 1))\n",
    "        FP = tf.count_nonzero((predict - 1) * labels)\n",
    "        precision = tf.divide(TP, TP + FP)\n",
    "        recall = tf.divide(TP, TP + FN)\n",
    "        precision = tf.cast(precision, dtype=tf.float64)\n",
    "        recall = tf.cast(recall, dtype=tf.float64)\n",
    "        #f1 = 2 * precision * recall / (precision + recall)\n",
    "        #f1 = tf.cast(f1, dtype=tf.float32)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/train_recall', recall)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/valid_recall', recall)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "def get_files(path_pos,path_neg,label_pos,label_neg):\n",
    "    TC = []\n",
    "    label_TC = []\n",
    "    nonTC = []\n",
    "    label_nonTC = []\n",
    "    # data loader\n",
    "    file_dir_TC=path_pos\n",
    "    file_dir_nonTC=path_neg\n",
    "    TC_list = os.listdir(file_dir_TC)\n",
    "    nonTC_list = os.listdir(file_dir_nonTC)\n",
    "    for file in TC_list[:len(nonTC_list)]:\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_pos:\n",
    "            TC.append(file_dir_TC + file)\n",
    "            label_TC.append(1)\n",
    "    for file in nonTC_list:\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_neg:\n",
    "            nonTC.append(file_dir_nonTC + file)\n",
    "            label_nonTC.append(0)\n",
    "    print(\"There are %d TC\\nThere are %d nonTC\" % (len(TC), len(nonTC)))\n",
    " \n",
    "    # shuffle\n",
    "    image_list = np.hstack((TC, nonTC))\n",
    "    label_list = np.hstack((label_TC, label_nonTC))\n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()    \n",
    "    np.random.shuffle(temp)\n",
    " \n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    " \n",
    "    return image_list, label_list\n",
    " \n",
    "# img_list,label_list = get_files(file_dir)\n",
    " \n",
    "# batch\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):   \n",
    "    image = tf.cast(image, tf.string)\n",
    "    label = tf.cast(label, tf.int32)\n",
    " \n",
    "    # queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    " \n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    label = input_queue[1]\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=1)\n",
    " \n",
    "    # resize\n",
    "    image = tf.image.resize_images(image, [image_H, image_W], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # image = tf.image.per_image_standardization(image)  \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,  \n",
    "                                              capacity=capacity)\n",
    "  \n",
    "    return tf.reshape(image_batch,[batch_size,image_W,image_H]), label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14355 TC\n",
      "There are 434488 nonTC\n",
      "X (1024, 128, 128)\n",
      "para_spt (1024, 4)\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_202/model.ckpt-1294000\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Session has been closed.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[node save/Assign_167 (defined at <ipython-input-17-434083799fa4>:36)  = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]\n\nCaused by op 'save/Assign_167', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-434083799fa4>\", line 36, in <module>\n    saver = tf.train.Saver()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 795, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 428, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 119, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[node save/Assign_167 (defined at <ipython-input-17-434083799fa4>:36)  = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[{{node save/Assign_167}} = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1546\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1547\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[node save/Assign_167 (defined at <ipython-input-17-434083799fa4>:36)  = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]\n\nCaused by op 'save/Assign_167', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-434083799fa4>\", line 36, in <module>\n    saver = tf.train.Saver()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 795, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 428, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 119, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[node save/Assign_167 (defined at <ipython-input-17-434083799fa4>:36)  = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-434083799fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#     variables_to_resotre = [v for v in varialbes if v.name.split('/')[0]!='softmax_linear']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------restore done---------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0msummary_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1580\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1582\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[node save/Assign_167 (defined at <ipython-input-17-434083799fa4>:36)  = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]\n\nCaused by op 'save/Assign_167', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-434083799fa4>\", line 36, in <module>\n    saver = tf.train.Saver()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n    self.build()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 795, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 428, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 119, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [18432,50] rhs shape= [2048,50]\n\t [[node save/Assign_167 (defined at <ipython-input-17-434083799fa4>:36)  = Assign[T=DT_FLOAT, _class=[\"loc:@dense/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense/kernel, save/RestoreV2/_377)]]\n\t [[{{node save/RestoreV2/_372}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_335_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:165)]]\n"
     ]
    }
   ],
   "source": [
    "##validation\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "N_CLASSES = 2 \n",
    "IMG_W = 128  # resize\n",
    "IMG_H = 128\n",
    "BATCH_SIZE = 1024\n",
    "CAPACITY = 20000\n",
    "MAX_STEP = 1000\n",
    "\n",
    "file_dir_valTC='/home/ubuntu/data/valTC_cp/'\n",
    "file_dir_valnonTC='/home/ubuntu/data/valnonTC/'\n",
    "\n",
    "valid, valid_label = get_files(file_dir_valTC,file_dir_valnonTC,'valTC','valnonTC')\n",
    "logs_valid_dir='./valid_attention_mask'\n",
    "\n",
    "valid_batch,valid_label_batch=get_batch(valid,\n",
    "                                valid_label,\n",
    "                                IMG_W,\n",
    "                                IMG_H,\n",
    "                                BATCH_SIZE,\n",
    "                                CAPACITY)\n",
    "\n",
    "#with tf.Graph().as_default():\n",
    "ckpt_path = './train_attention_202/model.ckpt-1294000'\n",
    "\n",
    "# x = tf.placeholder(tf.float32, [BATCH_SIZE,IMG_W,IMG_H,1])\n",
    "# y = tf.placeholder(tf.float32, [BATCH_SIZE])\n",
    "# y = tf.cast(y,tf.int64)\n",
    "\n",
    "train_logits = ResNet50_reference(valid_batch)\n",
    "valid__acc = evaluation(train_logits, valid_label_batch, 'valid')\n",
    "val_recall, val_precision = recall_precision(train_logits, valid_label_batch, 'valid')\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    #valid_batch,valid_label_batch=sess.run([valid_batch,valid_label_batch])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "#     variables = tf.contrib.framework.get_variables_to_restore()\n",
    "#     variables_to_resotre = [v for v in varialbes if v.name.split('/')[0]!='softmax_linear']\n",
    "\n",
    "    saver.restore(sess,ckpt_path)\n",
    "    print('--------restore done---------')\n",
    "    summary_op = tf.summary.merge_all() \n",
    "\n",
    "    valid_writer = tf.summary.FileWriter(logs_valid_dir, sess.graph)\n",
    "  \n",
    "    print('---------validation start----------')\n",
    "    for step in np.arange(MAX_STEP):  \n",
    "        try:        \n",
    "            for step in np.arange(MAX_STEP):\n",
    "                if coord.should_stop():\n",
    "                        break\n",
    "                val_acc_op, val_recall_op, val_precision_op = sess.run([valid__acc, val_recall, val_precision])\n",
    "                #val_acc, cal_recall, val_precision = sess.run([valid__acc, val_recall, val_precision],feed_dict={x:valid_batch,y:valid_label_batch})\n",
    "                print('Step %d, valid accuracy = %.2f%%, valid recall = %.2f%%, valid precision = %.2f%%' %(step, val_acc_op*100.0, val_recall_op*100.0, val_precision_op*100.0))\n",
    "\n",
    "                summary_str = sess.run(summary_op)\n",
    "                valid_writer.add_summary(summary_str, step)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done validation -- epoch limit reached')\n",
    "\n",
    "        finally:\n",
    "            coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
