{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell_impl import BasicLSTMCell\n",
    "from tensorflow.contrib.legacy_seq2seq.python.ops.seq2seq import rnn_decoder\n",
    "from tensorflow.python.ops.distributions.normal import Normal\n",
    "\n",
    "\n",
    "def _weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def _bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, w):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_3x3(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x3(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 3, 1], strides=[1, 2, 3, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_1x1(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def _log_likelihood(loc_means, locs, variance):\n",
    "    loc_means = tf.stack(loc_means)  # [timesteps, batch_sz, loc_dim]\n",
    "    locs = tf.stack(locs)\n",
    "    gaussian = Normal(loc_means, variance)\n",
    "    logll = gaussian._log_prob(x=locs)  # [timesteps, batch_sz, loc_dim]\n",
    "    logll = tf.reduce_sum(logll, 2)\n",
    "    return tf.transpose(logll)  # [batch_sz, timesteps]\n",
    "\n",
    "\n",
    "class RetinaSensor(object):\n",
    "    # one scale\n",
    "    def __init__(self, img_size_width, img_size_height, patch_window_width, patch_window_height):\n",
    "        self.img_size_width = img_size_width\n",
    "        self.img_size_height = img_size_height\n",
    "        self.patch_window_width = patch_window_width\n",
    "        self.patch_window_height = patch_window_height\n",
    "\n",
    "    def __call__(self, img_ph, loc):\n",
    "        img = tf.reshape(img_ph, [\n",
    "            tf.shape(img_ph)[0],\n",
    "            self.img_size_width,\n",
    "            self.img_size_height,\n",
    "            1\n",
    "        ])\n",
    "        '''\n",
    "        tf.image.extract_glimpse:\n",
    "        If the windows only partially\n",
    "        overlaps the inputs, the non overlapping areas will be filled with\n",
    "        random noise.\n",
    "        '''\n",
    "        pth = tf.image.extract_glimpse(\n",
    "\n",
    "            img, # input\n",
    "            [self.patch_window_width, self.patch_window_height], # size\n",
    "            loc) # offset\n",
    "        # pth: [tf.shape(img_ph)[0], patch_window_width, patch_window_height, 1]\n",
    "\n",
    "        return tf.reshape(pth, [tf.shape(loc)[0],\n",
    "                                self.patch_window_width * self.patch_window_height])\n",
    "\n",
    "\n",
    "class GlimpseNetwork(object):\n",
    "    def __init__(self, img_size_width, img_size_height,\n",
    "                 patch_window_width, patch_window_height,\n",
    "                 loc_dim, g_size, l_size, output_size):\n",
    "        self.retina_sensor = RetinaSensor(img_size_width, img_size_height,\n",
    "                                          patch_window_width, patch_window_height)\n",
    "\n",
    "        # layer 1\n",
    "        self.g1_w = _weight_variable((patch_window_width * patch_window_height, g_size))\n",
    "        self.g1_b = _bias_variable((g_size,))\n",
    "        self.l1_w = _weight_variable((loc_dim, l_size))\n",
    "        self.l1_b = _bias_variable((l_size,))\n",
    "        # layer 2\n",
    "        self.g2_w = _weight_variable((g_size, output_size))\n",
    "        self.g2_b = _bias_variable((output_size,))\n",
    "        self.l2_w = _weight_variable((l_size, output_size))\n",
    "        self.l2_b = _bias_variable((output_size,))\n",
    "\n",
    "    def __call__(self, imgs_ph, locs):\n",
    "        pths = self.retina_sensor(imgs_ph, locs)\n",
    "\n",
    "        g = tf.nn.xw_plus_b(tf.nn.relu(tf.nn.xw_plus_b(pths, self.g1_w, self.g1_b)),\n",
    "                            self.g2_w, self.g2_b)\n",
    "        l = tf.nn.xw_plus_b(tf.nn.relu(tf.nn.xw_plus_b(locs, self.l1_w, self.l1_b)),\n",
    "                            self.l2_w, self.l2_b)\n",
    "\n",
    "        return tf.nn.relu(g + l)\n",
    "\n",
    "\n",
    "class LocationNetwork(object):\n",
    "    def __init__(self, loc_dim, rnn_output_size, variance=0.22, is_sampling=False):\n",
    "        self.loc_dim = loc_dim  # 2, (x,y)\n",
    "        self.variance = variance\n",
    "        self.w = _weight_variable((rnn_output_size, loc_dim))\n",
    "        self.b = _bias_variable((loc_dim,))\n",
    "\n",
    "        self.is_sampling = is_sampling\n",
    "\n",
    "    def __call__(self, cell_output):\n",
    "        mean = tf.nn.xw_plus_b(cell_output, self.w, self.b)\n",
    "        mean = tf.clip_by_value(mean, -1., 1.)\n",
    "        mean = tf.stop_gradient(mean)\n",
    "\n",
    "        if self.is_sampling:\n",
    "            loc = mean + tf.random_normal(\n",
    "                (tf.shape(cell_output)[0], self.loc_dim),\n",
    "                stddev=self.variance)\n",
    "            loc = tf.clip_by_value(loc, -1., 1.)\n",
    "        else:\n",
    "            loc = mean\n",
    "        loc = tf.stop_gradient(loc)\n",
    "        return loc, mean\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, img_size_width, img_size_height,\n",
    "                 CNN_patch_width, CNN_patch_height, CNN_patch_number):\n",
    "        self.img_size_width = img_size_width\n",
    "        self.img_size_height = img_size_height\n",
    "        self.CNN_patch_width = CNN_patch_width\n",
    "        self.CNN_patch_height = CNN_patch_height\n",
    "        self.CNN_patch_number = CNN_patch_number\n",
    "\n",
    "    def __call__(self, imgs_ph):\n",
    "        imgs_ph = tf.reshape(imgs_ph, [-1, self.img_size_height, self.img_size_width, 1])\n",
    "        W_conv1 = _weight_variable(\n",
    "            [self.CNN_patch_width, self.CNN_patch_height, 1, self.CNN_patch_number]\n",
    "        )\n",
    "        # patch width x height, in size 1, out size patch_nb\n",
    "        b_conv1 = _bias_variable([self.CNN_patch_number])\n",
    "        h_conv1 = tf.nn.relu(conv2d(imgs_ph, W_conv1) + b_conv1)\n",
    "\n",
    "        W_fc1 = _weight_variable([self.img_size_height * self.img_size_width\n",
    "                                  * self.CNN_patch_number,\n",
    "                                  self.img_size_height * self.img_size_width])\n",
    "        b_fc1 = _bias_variable([self.img_size_height * self.img_size_width])\n",
    "        h_pool2_flat = tf.reshape(h_conv1,\n",
    "                                  [-1,\n",
    "                                   self.img_size_height * self.img_size_width\n",
    "                                   * self.CNN_patch_number]\n",
    "                                  )\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        # return tf.reshape(h_fc1, [-1, self.img_size_height, self.img_size_width, 1])\n",
    "        return h_fc1\n",
    "\n",
    "class RecurrentAttentionModel(object):\n",
    "    def __init__(self, img_size_width, img_size_height,\n",
    "                 CNN_patch_width, CNN_patch_height, CNN_patch_number,\n",
    "                 patch_window_width, patch_window_height, g_size, l_size, glimpse_output_size,\n",
    "                 loc_dim, variance,\n",
    "                 cell_size, num_glimpses, num_classes,\n",
    "                 learning_rate, learning_rate_decay_factor, min_learning_rate, training_batch_num,\n",
    "                 max_gradient_norm, last_lstm_size, n_time_window,\n",
    "                 is_training=False):\n",
    "\n",
    "        self.img_ph = tf.placeholder(tf.float32, [None, img_size_width * img_size_height])\n",
    "        self.lbl_ph = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        # decayed_learning_rate = learning_rate * decay_rate ^ (global_step / training_batch_num)\n",
    "        self.learning_rate = tf.maximum(tf.train.exponential_decay(\n",
    "            learning_rate, self.global_step,\n",
    "            training_batch_num, # batch number\n",
    "            learning_rate_decay_factor,\n",
    "            # If the argument staircase is True,\n",
    "            # then global_step / decay_steps is an integer division\n",
    "            # and the decayed learning rate follows a staircase function.\n",
    "            staircase=True),\n",
    "            min_learning_rate)\n",
    "\n",
    "        cell = BasicLSTMCell(cell_size)\n",
    "\n",
    "        with tf.variable_scope('CNN'):\n",
    "            cnn_network = CNN(img_size_width, img_size_height,\n",
    "                              CNN_patch_width, CNN_patch_height, CNN_patch_number)\n",
    "\n",
    "        with tf.variable_scope('GlimpseNetwork'):\n",
    "            glimpse_network = GlimpseNetwork(img_size_width,\n",
    "                                             img_size_height,\n",
    "                                             patch_window_width,\n",
    "                                             patch_window_height,\n",
    "                                             loc_dim,\n",
    "                                             g_size,\n",
    "                                             l_size,\n",
    "                                             glimpse_output_size)\n",
    "        with tf.variable_scope('LocationNetwork'):\n",
    "            location_network = LocationNetwork(loc_dim=loc_dim,\n",
    "                                               rnn_output_size=cell.output_size, # cell_size\n",
    "                                               variance=variance,\n",
    "                                               is_sampling=is_training)\n",
    "\n",
    "        # Core Network\n",
    "        self.img_ph = cnn_network(self.img_ph)\n",
    "        batch_size = tf.shape(self.img_ph)[0]  # training_batch_size * M\n",
    "        init_loc = tf.random_uniform((batch_size, loc_dim), minval=-1, maxval=1)\n",
    "        # shape: (batch_size, loc_dim), range: [-1,1)\n",
    "        init_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        init_glimpse = glimpse_network(self.img_ph, init_loc)\n",
    "        rnn_inputs = [init_glimpse]\n",
    "        rnn_inputs.extend([0] * num_glimpses)\n",
    "\n",
    "        self.locs, loc_means = [], []\n",
    "\n",
    "        def loop_function(prev, _):\n",
    "            loc, loc_mean = location_network(prev)\n",
    "            self.locs.append(loc)\n",
    "            loc_means.append(loc_mean)\n",
    "            glimpse = glimpse_network(self.img_ph, loc)\n",
    "            return glimpse\n",
    "\n",
    "        rnn_outputs, _ = rnn_decoder(rnn_inputs, init_state, cell, loop_function=loop_function)\n",
    "\n",
    "        # Time independent baselines\n",
    "        with tf.variable_scope('Baseline'):\n",
    "            baseline_w = _weight_variable((cell.output_size, 1))\n",
    "            baseline_b = _bias_variable((1,))\n",
    "        baselines = []\n",
    "        for output in rnn_outputs[1:]:\n",
    "            baseline = tf.nn.xw_plus_b(output, baseline_w, baseline_b)\n",
    "            baseline = tf.squeeze(baseline)\n",
    "            baselines.append(baseline)\n",
    "        baselines = tf.stack(baselines)  # [timesteps, batch_sz]\n",
    "        baselines = tf.transpose(baselines)  # [batch_sz, timesteps]\n",
    "\n",
    "        # Classification. Take the last step only.\n",
    "        rnn_last_output = rnn_outputs[-1]\n",
    "        with tf.variable_scope('Classification'):\n",
    "            logit_w = _weight_variable((cell.output_size, num_classes))\n",
    "            logit_b = _bias_variable((num_classes,))\n",
    "        logits = tf.nn.xw_plus_b(rnn_last_output, logit_w, logit_b)\n",
    "        self.prediction = tf.argmax(logits, 1)\n",
    "        self.softmax = tf.nn.softmax(logits)\n",
    "\n",
    "        with tf.variable_scope('LSTM_Classification'):\n",
    "            last_lstm_w_in = _weight_variable((cell.output_size, last_lstm_size))\n",
    "            last_lstm_b_in = _bias_variable((last_lstm_size,))\n",
    "            print('rnn_last_output',np.shape(rnn_last_output),tf.shape(rnn_last_output))\n",
    "            print('last_lstm_w_in',np.shape(last_lstm_w_in),tf.shape(last_lstm_w_in))\n",
    "            last_lstm_in = tf.matmul(rnn_last_output, last_lstm_w_in) + last_lstm_b_in\n",
    "            print('last_lstm_w_in_1',np.shape(last_lstm_w_in),tf.shape(last_lstm_w_in))\n",
    "            last_lstm_in = tf.reshape(last_lstm_in, [-1, n_time_window, last_lstm_size])\n",
    "            print('last_lstm_w_in_2',np.shape(last_lstm_w_in),tf.shape(last_lstm_w_in))\n",
    "\n",
    "            if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "                cell = tf.nn.rnn_cell.BasicLSTMCell(last_lstm_size, forget_bias=1.0, state_is_tuple=True)\n",
    "            else:\n",
    "                cell = tf.contrib.rnn.BasicLSTMCell(last_lstm_size)\n",
    "            # lstm cell is divided into two parts (c_state, h_state)\n",
    "            init_state_last_lstm = cell.zero_state(batch_size // n_time_window, dtype=tf.float32)\n",
    "            lstm_outputs, final_state = tf.nn.dynamic_rnn(cell, last_lstm_in,\n",
    "                                                     initial_state=init_state_last_lstm, time_major=False)\n",
    "            last_lstm_w_out = _weight_variable((cell.output_size, num_classes))\n",
    "            last_lstm_b_out = _bias_variable((num_classes,))\n",
    "\n",
    "            if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "                lstm_outputs = tf.unpack(tf.transpose(lstm_outputs, [1, 0, 2]))  # states is the last outputs\n",
    "            else:\n",
    "                lstm_outputs = tf.unstack(tf.transpose(lstm_outputs, [1, 0, 2]))\n",
    "            lstm_logits = tf.matmul(lstm_outputs[-1], last_lstm_w_out) + last_lstm_b_out\n",
    "            lstm_logits = tf.reshape(tf.tile(lstm_logits, (1, n_time_window)), [-1, num_classes])\n",
    "            self.lstm_prediction = tf.argmax(lstm_logits, 1)\n",
    "            self.lstm_softmax = tf.nn.softmax(lstm_logits)\n",
    "\n",
    "\n",
    "\n",
    "        if is_training:\n",
    "            # classification loss\n",
    "            self.cross_entropy = tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.lbl_ph, logits=logits))\n",
    "            self.lstm_cross_entropy = tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.lbl_ph, logits=lstm_logits))\n",
    "            # RL reward\n",
    "            reward = tf.cast(tf.equal(self.prediction, self.lbl_ph), tf.float32)\n",
    "            rewards = tf.expand_dims(reward, 1)  # [batch_sz, 1]\n",
    "            rewards = tf.tile(rewards, (1, num_glimpses))  # [batch_sz, timesteps]\n",
    "            advantages = rewards - tf.stop_gradient(baselines)\n",
    "            self.advantage = tf.reduce_mean(advantages)\n",
    "            logll = _log_likelihood(loc_means, self.locs, variance)\n",
    "            logllratio = tf.reduce_mean(logll * advantages)\n",
    "            self.reward = tf.reduce_mean(reward)\n",
    "            # baseline loss\n",
    "            self.baselines_mse = tf.reduce_mean(tf.square((rewards - baselines)))\n",
    "            # hybrid loss\n",
    "            self.loss = -logllratio + self.cross_entropy + self.baselines_mse + self.lstm_cross_entropy\n",
    "            params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.loss, params)\n",
    "            clipped_gradients, norm = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
    "            self.train_op = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(\n",
    "                zip(clipped_gradients, params), global_step=self.global_step)\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(logits, labels, name):\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits \\\n",
    "            (logits=logits, labels=labels, name='xentropy_per_example')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_loss', loss)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_loss', loss)\n",
    "    return loss\n",
    " \n",
    "def trainning(loss, learning_rate):\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_op = optimizer.minimize(loss, global_step= global_step)\n",
    "    return train_op\n",
    " \n",
    "def evaluation(logits, labels, name):\n",
    "    with tf.variable_scope('accuracy') as scope:\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        correct = tf.cast(correct, tf.float16)\n",
    "        accuracy = tf.reduce_mean(correct)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_accuracy', accuracy)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_accuracy', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def recall_precision(logits, labels, name):\n",
    "    logits = tf.cast(logits, tf.int64)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    predict = tf.arg_max(logits,1)\n",
    "    with tf.variable_scope('recall_precision') as scope:\n",
    "        TP = tf.count_nonzero(predict * labels)\n",
    "        TN = tf.count_nonzero((predict - 1) * (labels - 1))\n",
    "        FN = tf.count_nonzero(predict * (labels - 1))\n",
    "        FP = tf.count_nonzero((predict - 1) * labels)\n",
    "        precision = tf.divide(TP, TP + FP)\n",
    "        recall = tf.divide(TP, TP + FN)\n",
    "        precision = tf.cast(precision, dtype=tf.float64)\n",
    "        recall = tf.cast(recall, dtype=tf.float64)\n",
    "        #f1 = 2 * precision * recall / (precision + recall)\n",
    "        #f1 = tf.cast(f1, dtype=tf.float32)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/train_recall', recall)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/valid_recall', recall)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "def get_files(path_pos,path_neg,label_pos,label_neg):\n",
    "    TC = []\n",
    "    label_TC = []\n",
    "    nonTC = []\n",
    "    label_nonTC = []\n",
    "    # data loader\n",
    "    file_dir_TC=path_pos\n",
    "    file_dir_nonTC=path_neg\n",
    "    TC_list = os.listdir(file_dir_TC)\n",
    "    nonTC_list = os.listdir(file_dir_nonTC)\n",
    "    for file in TC_list[:len(nonTC_list)]:\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_pos:\n",
    "            TC.append(file_dir_TC + file)\n",
    "            label_TC.append(1)\n",
    "    for file in nonTC_list:\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_neg:\n",
    "            nonTC.append(file_dir_nonTC + file)\n",
    "            label_nonTC.append(0)\n",
    "    print(\"There are %d TC\\nThere are %d nonTC\" % (len(TC), len(nonTC)))\n",
    " \n",
    "    # shuffle\n",
    "    image_list = np.hstack((TC, nonTC))\n",
    "    label_list = np.hstack((label_TC, label_nonTC))\n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()    \n",
    "    np.random.shuffle(temp)\n",
    " \n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    " \n",
    "    return image_list, label_list\n",
    " \n",
    "# img_list,label_list = get_files(file_dir)\n",
    " \n",
    "# batch\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):   \n",
    "    image = tf.cast(image, tf.string)\n",
    "    label = tf.cast(label, tf.int32)\n",
    " \n",
    "    # queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    " \n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    label = input_queue[1]\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=1)\n",
    " \n",
    "    # resize\n",
    "    image = tf.image.resize_images(image, [image_H, image_W], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # image = tf.image.per_image_standardization(image)  \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,  \n",
    "                                              capacity=capacity)\n",
    "  \n",
    "    return tf.reshape(image_batch,[batch_size,image_W,image_H]), label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1737956 TC\n",
      "There are 1737956 nonTC\n",
      "There are 57420 TC\n",
      "There are 434488 nonTC\n",
      "WARNING:tensorflow:From <ipython-input-3-355d52689273>:46: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:372: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:318: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-3-355d52689273>:59: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From <ipython-input-1-cdc0fadeaa93>:186: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "rnn_last_output (?, 100) Tensor(\"LSTM_Classification/Shape:0\", shape=(2,), dtype=int32)\n",
      "last_lstm_w_in (100, 32) Tensor(\"LSTM_Classification/Shape_1:0\", shape=(2,), dtype=int32)\n",
      "last_lstm_w_in_1 (100, 32) Tensor(\"LSTM_Classification/Shape_2:0\", shape=(2,), dtype=int32)\n",
      "last_lstm_w_in_2 (100, 32) Tensor(\"LSTM_Classification/Shape_3:0\", shape=(2,), dtype=int32)\n",
      "WARNING:tensorflow:From <ipython-input-2-f1bd2d052cd6>:33: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From <ipython-input-4-545b9108c43e>:116: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "----------training start---------\n",
      "Step 0, train loss = 1.72, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 50, train loss = 1.63, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 100, train loss = 1.63, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 150, train loss = 1.61, train accuracy = 56.25%, train recall = 0.00%, train precision = nan%\n",
      "Step 200, train loss = 1.66, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 250, train loss = 1.64, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 300, train loss = 1.68, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 350, train loss = 1.61, train accuracy = 41.41%, train recall = 0.00%, train precision = nan%\n",
      "Step 400, train loss = 1.63, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 450, train loss = 1.65, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 500, train loss = 1.65, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-0\n",
      "*********************\n",
      "Step 500, valid loss = 0.69, valid accuracy = 14.06%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 550, train loss = 1.64, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 600, train loss = 1.62, train accuracy = 56.25%, train recall = 0.00%, train precision = nan%\n",
      "Step 650, train loss = 1.63, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 700, train loss = 1.62, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 750, train loss = 1.64, train accuracy = 57.03%, train recall = 0.00%, train precision = nan%\n",
      "Step 800, train loss = 1.64, train accuracy = 51.56%, train recall = 0.00%, train precision = nan%\n",
      "Step 850, train loss = 1.62, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 900, train loss = 1.62, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "Step 950, train loss = 1.65, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 1000, train loss = 1.63, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-500\n",
      "*********************\n",
      "Step 1000, valid loss = 0.69, valid accuracy = 14.06%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 1050, train loss = 1.63, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 1100, train loss = 1.66, train accuracy = 43.75%, train recall = 0.00%, train precision = nan%\n",
      "Step 1150, train loss = 1.63, train accuracy = 51.56%, train recall = 0.00%, train precision = nan%\n",
      "Step 1200, train loss = 1.63, train accuracy = 40.62%, train recall = 0.00%, train precision = nan%\n",
      "Step 1250, train loss = 1.64, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 1300, train loss = 1.63, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 1350, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 1400, train loss = 1.63, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 1450, train loss = 1.61, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 1500, train loss = 1.61, train accuracy = 58.59%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-1000\n",
      "*********************\n",
      "Step 1500, valid loss = 0.69, valid accuracy = 16.41%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 1550, train loss = 1.63, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 1600, train loss = 1.64, train accuracy = 51.56%, train recall = 0.00%, train precision = nan%\n",
      "Step 1650, train loss = 1.63, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1700, train loss = 1.63, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "Step 1750, train loss = 1.64, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 1800, train loss = 1.65, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 1850, train loss = 1.63, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 1900, train loss = 1.62, train accuracy = 54.69%, train recall = 0.00%, train precision = nan%\n",
      "Step 1950, train loss = 1.65, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "Step 2000, train loss = 1.63, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-1500\n",
      "*********************\n",
      "Step 2000, valid loss = 0.69, valid accuracy = 10.94%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 2050, train loss = 1.63, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 2100, train loss = 1.62, train accuracy = 42.19%, train recall = 0.00%, train precision = nan%\n",
      "Step 2150, train loss = 1.63, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 2200, train loss = 1.66, train accuracy = 37.50%, train recall = 0.00%, train precision = nan%\n",
      "Step 2250, train loss = 1.62, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 2300, train loss = 1.63, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 2350, train loss = 1.61, train accuracy = 42.97%, train recall = 0.00%, train precision = nan%\n",
      "Step 2400, train loss = 1.64, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 2450, train loss = 1.63, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 2500, train loss = 1.64, train accuracy = 62.50%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-2000\n",
      "*********************\n",
      "Step 2500, valid loss = 0.69, valid accuracy = 17.97%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 2550, train loss = 1.63, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "Step 2600, train loss = 1.65, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 2650, train loss = 1.65, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 2700, train loss = 1.62, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "Step 2750, train loss = 1.64, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 2800, train loss = 1.64, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "Step 2850, train loss = 1.63, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 2900, train loss = 1.63, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 2950, train loss = 1.61, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "Step 3000, train loss = 1.61, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-2500\n",
      "*********************\n",
      "Step 3000, valid loss = 0.69, valid accuracy = 14.06%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 3050, train loss = 1.67, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 3100, train loss = 1.67, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 3150, train loss = 1.63, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 3200, train loss = 1.64, train accuracy = 54.69%, train recall = 0.00%, train precision = nan%\n",
      "Step 3250, train loss = 1.65, train accuracy = 58.59%, train recall = 0.00%, train precision = nan%\n",
      "Step 3300, train loss = 1.62, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "Step 3350, train loss = 1.63, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 3400, train loss = 1.65, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 3450, train loss = 1.64, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 3500, train loss = 1.65, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-3000\n",
      "*********************\n",
      "Step 3500, valid loss = 0.69, valid accuracy = 8.59%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 3550, train loss = 1.62, train accuracy = 57.03%, train recall = 0.00%, train precision = nan%\n",
      "Step 3600, train loss = 1.63, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 3650, train loss = 1.67, train accuracy = 55.47%, train recall = 0.00%, train precision = nan%\n",
      "Step 3700, train loss = 1.62, train accuracy = 56.25%, train recall = 0.00%, train precision = nan%\n",
      "Step 3750, train loss = 1.63, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 3800, train loss = 1.64, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 3850, train loss = 1.64, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 3900, train loss = 1.65, train accuracy = 57.03%, train recall = 0.00%, train precision = nan%\n",
      "Step 3950, train loss = 1.63, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 4000, train loss = 1.63, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-3500\n",
      "*********************\n",
      "Step 4000, valid loss = 0.69, valid accuracy = 10.16%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 4050, train loss = 1.64, train accuracy = 46.88%, train recall = 0.00%, train precision = nan%\n",
      "Step 4100, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 4150, train loss = 1.64, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 4200, train loss = 1.65, train accuracy = 51.56%, train recall = 0.00%, train precision = nan%\n",
      "Step 4250, train loss = 1.64, train accuracy = 54.69%, train recall = 0.00%, train precision = nan%\n",
      "Step 4300, train loss = 1.64, train accuracy = 46.88%, train recall = 0.00%, train precision = nan%\n",
      "Step 4350, train loss = 1.66, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 4400, train loss = 1.61, train accuracy = 40.62%, train recall = 0.00%, train precision = nan%\n",
      "Step 4450, train loss = 1.63, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 4500, train loss = 1.62, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-4000\n",
      "*********************\n",
      "Step 4500, valid loss = 0.69, valid accuracy = 7.81%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 4550, train loss = 1.62, train accuracy = 57.03%, train recall = 0.00%, train precision = nan%\n",
      "Step 4600, train loss = 1.66, train accuracy = 63.28%, train recall = 0.00%, train precision = nan%\n",
      "Step 4650, train loss = 1.65, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "Step 4700, train loss = 1.64, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 4750, train loss = 1.64, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 4800, train loss = 1.67, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 4850, train loss = 1.62, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 4900, train loss = 1.63, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 4950, train loss = 1.62, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 5000, train loss = 1.61, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-4500\n",
      "*********************\n",
      "Step 5000, valid loss = 0.69, valid accuracy = 14.84%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5050, train loss = 1.64, train accuracy = 46.88%, train recall = 0.00%, train precision = nan%\n",
      "Step 5100, train loss = 1.63, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 5150, train loss = 1.67, train accuracy = 56.25%, train recall = 0.00%, train precision = nan%\n",
      "Step 5200, train loss = 1.62, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 5250, train loss = 1.66, train accuracy = 63.28%, train recall = 0.00%, train precision = nan%\n",
      "Step 5300, train loss = 1.65, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 5350, train loss = 1.66, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 5400, train loss = 1.62, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 5450, train loss = 1.64, train accuracy = 45.31%, train recall = 0.00%, train precision = nan%\n",
      "Step 5500, train loss = 1.65, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-5000\n",
      "*********************\n",
      "Step 5500, valid loss = 0.69, valid accuracy = 10.16%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 5550, train loss = 1.65, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 5600, train loss = 1.65, train accuracy = 58.59%, train recall = 0.00%, train precision = nan%\n",
      "Step 5650, train loss = 1.64, train accuracy = 55.47%, train recall = 0.00%, train precision = nan%\n",
      "Step 5700, train loss = 1.63, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 5750, train loss = 1.65, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 5800, train loss = 1.63, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 5850, train loss = 1.63, train accuracy = 54.69%, train recall = 0.00%, train precision = nan%\n",
      "Step 5900, train loss = 1.65, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 5950, train loss = 1.62, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 6000, train loss = 1.65, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-5500\n",
      "*********************\n",
      "Step 6000, valid loss = 0.69, valid accuracy = 13.28%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 6050, train loss = 1.63, train accuracy = 42.97%, train recall = 0.00%, train precision = nan%\n",
      "Step 6100, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 6150, train loss = 1.71, train accuracy = 39.84%, train recall = 0.00%, train precision = nan%\n",
      "Step 6200, train loss = 1.65, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 6250, train loss = 1.65, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 6300, train loss = 1.64, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 6350, train loss = 1.65, train accuracy = 42.19%, train recall = 0.00%, train precision = nan%\n",
      "Step 6400, train loss = 1.62, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "Step 6450, train loss = 1.70, train accuracy = 62.50%, train recall = 0.00%, train precision = nan%\n",
      "Step 6500, train loss = 1.65, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-6000\n",
      "*********************\n",
      "Step 6500, valid loss = 0.69, valid accuracy = 12.50%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 6550, train loss = 1.63, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 6600, train loss = 1.65, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 6650, train loss = 1.65, train accuracy = 51.56%, train recall = 0.00%, train precision = nan%\n",
      "Step 6700, train loss = 1.63, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "Step 6750, train loss = 1.65, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 6800, train loss = 1.64, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 6850, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 6900, train loss = 1.65, train accuracy = 49.22%, train recall = 0.00%, train precision = nan%\n",
      "Step 6950, train loss = 1.61, train accuracy = 54.69%, train recall = 0.00%, train precision = nan%\n",
      "Step 7000, train loss = 1.65, train accuracy = 63.28%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-6500\n",
      "*********************\n",
      "Step 7000, valid loss = 0.69, valid accuracy = 8.59%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 7050, train loss = 1.66, train accuracy = 46.88%, train recall = 0.00%, train precision = nan%\n",
      "Step 7100, train loss = 1.63, train accuracy = 54.69%, train recall = 0.00%, train precision = nan%\n",
      "Step 7150, train loss = 1.62, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 7200, train loss = 1.65, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 7250, train loss = 1.67, train accuracy = 42.19%, train recall = 0.00%, train precision = nan%\n",
      "Step 7300, train loss = 1.63, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "Step 7350, train loss = 1.64, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 7400, train loss = 1.67, train accuracy = 42.97%, train recall = 0.00%, train precision = nan%\n",
      "Step 7450, train loss = 1.65, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 7500, train loss = 1.63, train accuracy = 43.75%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-7000\n",
      "*********************\n",
      "Step 7500, valid loss = 0.69, valid accuracy = 9.38%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 7550, train loss = 1.64, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 7600, train loss = 1.64, train accuracy = 47.66%, train recall = 0.00%, train precision = nan%\n",
      "Step 7650, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 7700, train loss = 1.62, train accuracy = 56.25%, train recall = 0.00%, train precision = nan%\n",
      "Step 7750, train loss = 1.62, train accuracy = 58.59%, train recall = 0.00%, train precision = nan%\n",
      "Step 7800, train loss = 1.64, train accuracy = 51.56%, train recall = 0.00%, train precision = nan%\n",
      "Step 7850, train loss = 1.64, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 7900, train loss = 1.63, train accuracy = 52.34%, train recall = 0.00%, train precision = nan%\n",
      "Step 7950, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 8000, train loss = 1.65, train accuracy = 50.00%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-7500\n",
      "*********************\n",
      "Step 8000, valid loss = 0.69, valid accuracy = 9.38%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 8050, train loss = 1.64, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 8100, train loss = 1.61, train accuracy = 55.47%, train recall = 0.00%, train precision = nan%\n",
      "Step 8150, train loss = 1.65, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 8200, train loss = 1.63, train accuracy = 44.53%, train recall = 0.00%, train precision = nan%\n",
      "Step 8250, train loss = 1.64, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 8300, train loss = 1.65, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 8350, train loss = 1.63, train accuracy = 48.44%, train recall = 0.00%, train precision = nan%\n",
      "Step 8400, train loss = 1.61, train accuracy = 55.47%, train recall = 0.00%, train precision = nan%\n",
      "Step 8450, train loss = 1.63, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8500, train loss = 1.63, train accuracy = 53.12%, train recall = 0.00%, train precision = nan%\n",
      "INFO:tensorflow:Restoring parameters from ./train_attention_resnet_RAM/model.ckpt-8000\n",
      "*********************\n",
      "Step 8500, valid loss = 0.69, valid accuracy = 13.28%, valid recall = 0.00%, valid precision = nan%\n",
      "*********************\n",
      "Step 8550, train loss = 1.64, train accuracy = 53.91%, train recall = 0.00%, train precision = nan%\n",
      "Step 8600, train loss = 1.64, train accuracy = 50.78%, train recall = 0.00%, train precision = nan%\n",
      "Step 8650, train loss = 1.65, train accuracy = 55.47%, train recall = 0.00%, train precision = nan%\n",
      "Step 8700, train loss = 1.62, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n",
      "Step 8750, train loss = 1.62, train accuracy = 46.09%, train recall = 0.00%, train precision = nan%\n"
     ]
    }
   ],
   "source": [
    "##validation\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay_factor = 0.97\n",
    "min_learning_rate = 1e-6\n",
    "max_gradient_norm = 5.0\n",
    "num_steps = 100000\n",
    "\n",
    "CNN_patch_width = 5\n",
    "CNN_patch_height = 5\n",
    "CNN_patch_number = 32\n",
    "\n",
    "patch_window_width = 32 # size of glimpse window size\n",
    "patch_window_height = 32\n",
    "g_size = 128 # Size of theta_g^0\n",
    "l_size = 128 # Size of theta_g^1\n",
    "glimpse_output_size = 220 # Output size of Glimpse Network\n",
    "cell_size = 100 # Size of LSTM cell\n",
    "num_glimpses = 30 # Number of glimpses\n",
    "variance = 0.22 # Gaussian variance for Location Network\n",
    "M = 20 # Monte Carlo sampling, see Eq(2)\n",
    "\n",
    "n_time_window = 128\n",
    "last_lstm_size = 32\n",
    "\n",
    "batch_size = 128\n",
    "class_num = 2\n",
    "\n",
    "N_CLASSES = 2 \n",
    "IMG_W = 64 # resize\n",
    "IMG_H = 64\n",
    "BATCH_SIZE = 128\n",
    "CAPACITY = 20000\n",
    "MAX_STEP = 10000000\n",
    "training_batch_num = 10000000\n",
    "\n",
    "train_dir = './train_attention_resnet_RAM/'\n",
    "logs_train_dir = './train_attention_resnet_RAM/'\n",
    "\n",
    "file_dir_TC='/home/ubuntu/data/TC/'\n",
    "file_dir_nonTC='/home/ubuntu/data/nonTC/'\n",
    "file_dir_valTC='/home/ubuntu/data/valTC_cp/'\n",
    "file_dir_valnonTC='/home/ubuntu/data/valnonTC/'\n",
    "\n",
    "train, train_label = get_files(file_dir_TC,file_dir_nonTC,'TC','nonTC')\n",
    "valid, valid_label = get_files(file_dir_valTC,file_dir_valnonTC,'valTC','valnonTC')\n",
    "train_batch_op,train_label_batch_op=get_batch(train,\n",
    "                                train_label,\n",
    "                                IMG_W,\n",
    "                                IMG_H,\n",
    "                                BATCH_SIZE,\n",
    "                                CAPACITY)\n",
    "\n",
    "valid_batch_op,valid_label_batch_op=get_batch(valid,\n",
    "                                valid_label,\n",
    "                                IMG_W,\n",
    "                                IMG_H,\n",
    "                                BATCH_SIZE,\n",
    "                                CAPACITY)\n",
    "x = tf.placeholder(tf.float32, [BATCH_SIZE,IMG_W,IMG_H,1])\n",
    "y = tf.placeholder(tf.float32, [BATCH_SIZE])\n",
    "y = tf.cast(y,tf.int64)\n",
    "\n",
    "ram = RecurrentAttentionModel(img_size_width=64,\n",
    "                              img_size_height = 64,\n",
    "                              CNN_patch_width = CNN_patch_width,\n",
    "                              CNN_patch_height = CNN_patch_height,\n",
    "                              CNN_patch_number = CNN_patch_number,\n",
    "                              patch_window_width = patch_window_width,\n",
    "                              patch_window_height=patch_window_height,\n",
    "                              g_size=g_size,\n",
    "                              l_size=l_size,\n",
    "                              glimpse_output_size=glimpse_output_size,\n",
    "                              loc_dim=2,   # (x,y)\n",
    "                              variance=variance,\n",
    "                              cell_size=cell_size,\n",
    "                              num_glimpses=num_glimpses,\n",
    "                              num_classes=class_num,\n",
    "                              learning_rate=learning_rate,\n",
    "                              learning_rate_decay_factor=learning_rate_decay_factor,\n",
    "                              min_learning_rate=min_learning_rate,\n",
    "                              training_batch_num=training_batch_num,\n",
    "                              max_gradient_norm=max_gradient_norm,\n",
    "                              last_lstm_size=last_lstm_size,\n",
    "                              n_time_window=n_time_window,\n",
    "                              is_training=True)\n",
    "output_feed = [ram.train_op, ram.loss,\n",
    "                             ram.cross_entropy, ram.reward,\n",
    "                             ram.advantage, ram.baselines_mse,\n",
    "                             ram.learning_rate]\n",
    "train_logits = ram.lstm_softmax \n",
    "train_loss = ram.loss\n",
    "train_op = ram.train_op\n",
    "train_acc = evaluation(ram.lstm_softmax , y, 'train')\n",
    "train_recall, train_precision = recall_precision(ram.lstm_softmax , y, 'train')\n",
    "\n",
    "valid_loss = losses(ram.lstm_softmax , y, 'valid')\n",
    "valid_acc = evaluation(ram.lstm_softmax , y, 'valid')\n",
    "valid_recall, valid_precision = recall_precision(ram.lstm_softmax , y, 'valid')\n",
    "\n",
    "summary_op = tf.summary.merge_all() \n",
    " \n",
    "sess = tf.Session()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(logs_train_dir, sess.graph)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    " \n",
    "try:\n",
    "    print('----------training start---------')\n",
    "    train_result=[]\n",
    "    valid_result=[]\n",
    "    for step in np.arange(MAX_STEP):\n",
    "        train_batch,train_label_batch = sess.run([train_batch_op,train_label_batch_op])\n",
    "        train_batch = np.reshape(train_batch,[BATCH_SIZE,-1])\n",
    "        if coord.should_stop():\n",
    "                break\n",
    "        _, tra_loss, cross_entropy, reward, advantage, baselines_mse, learning_rate = sess.run(output_feed,\n",
    "                                                                                 feed_dict={\n",
    "                                                                                      ram.img_ph: train_batch,\n",
    "                                                                                      ram.lbl_ph: train_label_batch\n",
    "                                                                                    })\n",
    "       \n",
    "        tra_acc, tra_recall, tra_precision= sess.run([train_acc, train_recall, train_precision],feed_dict={ram.img_ph: train_batch,\n",
    "                                                                                                           ram.lbl_ph: train_label_batch, \n",
    "                                                                                                           y:train_label_batch})\n",
    "        summary_str = sess.run(summary_op,feed_dict={ram.img_ph: train_batch, \n",
    "                                                     ram.lbl_ph: train_label_batch,\n",
    "                                                     y:train_label_batch})\n",
    "        summary = tf.Summary()\n",
    "        summary.value.add(tag='tra_loss', simple_value=tra_loss)\n",
    "        summary.value.add(tag='tra_acc', simple_value=tra_acc)\n",
    "        summary.value.add(tag='tra_recall', simple_value=tra_recall)\n",
    "        summary.value.add(tag='tra_precision', simple_value=tra_precision)\n",
    "        train_writer.add_summary(summary, step)\n",
    "        train_result.append([step, tra_loss, tra_acc*100.0, tra_recall*100.0, tra_precision*100.0])\n",
    "        if step % 50 == 0:\n",
    "            print('Step %d, train loss = %.2f, train accuracy = %.2f%%, train recall = %.2f%%, train precision = %.2f%%' %(step, tra_loss, tra_acc*100.0, tra_recall*100.0, tra_precision*100.0))\n",
    "            \n",
    "            \n",
    "        if step % 500 == 0:\n",
    "            ckpt=tf.train.get_checkpoint_state('./train_attention_resnet_RAM/')\n",
    "#             print(ckpt)\n",
    "            if ckpt and ckpt.all_model_checkpoint_paths:\n",
    "                valid_batch,valid_label_batch = sess.run([valid_batch_op,valid_label_batch_op])\n",
    "                valid_batch = np.reshape(valid_batch,[BATCH_SIZE,-1])\n",
    "                saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "                val_loss, val_acc, val_recall, val_precision = sess.run([valid_loss, valid_acc, valid_recall, valid_precision], feed_dict={ram.img_ph: valid_batch, \n",
    "                                                                                                                                           ram.lbl_ph: valid_label_batch,\n",
    "                                                                                                                                           y:valid_label_batch})\n",
    "                valid_result.append([step, val_loss, val_acc*100.0, val_recall*100.0, val_precision*100.0])\n",
    "                print('*********************')\n",
    "                print('Step %d, valid loss = %.2f, valid accuracy = %.2f%%, valid recall = %.2f%%, valid precision = %.2f%%' %(step, val_loss, val_acc*100.0, val_recall*100.0, val_precision*100.0))\n",
    "                print('*********************')\n",
    "                summary = tf.Summary()\n",
    "                summary.value.add(tag='val_loss', simple_value=val_loss)\n",
    "                summary.value.add(tag='val_acc', simple_value=val_acc)\n",
    "                summary.value.add(tag='val_recall', simple_value=val_recall)\n",
    "                summary.value.add(tag='val_precision', simple_value=val_precision)\n",
    "                train_writer.add_summary(summary, step)\n",
    "#                 summary_str = sess.run(summary_op,feed_dict={x:valid_batch,y:valid_label_batch})\n",
    "#                 train_writer.add_summary(summary_str, step)\n",
    "            \n",
    "      \n",
    "        if step % 500 == 0 or (step + 1) == MAX_STEP:\n",
    "            checkpoint_path = os.path.join(logs_train_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training -- epoch limit reached')\n",
    "\n",
    "finally:\n",
    "    coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
