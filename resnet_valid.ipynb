{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# set Ture during training, False during testing\n",
    "TRAINING = True\n",
    "\n",
    "\n",
    "def identity_block(X_input, kernel_size, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    with tf.name_scope(\"id_block_stage\"+str(stage)):\n",
    "        filter1, filter2, filter3 = filters\n",
    "        X_shortcut = X_input\n",
    "\n",
    "        # First component of main path\n",
    "        x = tf.layers.conv2d(X_input, filter1,\n",
    "                 kernel_size=(1, 1), strides=(1, 1),name=conv_name_base+'2a')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base+'2a', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Second component of main path\n",
    "        x = tf.layers.conv2d(x, filter2, (kernel_size, kernel_size),\n",
    "                                 padding='same', name=conv_name_base+'2b')\n",
    "        # batch_norm2 = tf.layers.batch_normalization(conv2, axis=3, name=bn_name_base+'2b', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Third component of main path\n",
    "        x = tf.layers.conv2d(x, filter3, kernel_size=(1, 1),name=conv_name_base+'2c')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2c', training=TRAINING)\n",
    "\n",
    "        # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "        X_add_shortcut = tf.add(x, X_shortcut)\n",
    "        add_result = tf.nn.relu(X_add_shortcut)\n",
    "\n",
    "    return add_result\n",
    "\n",
    "\n",
    "def convolutional_block(X_input, kernel_size, filters, stage, block, stride = 2):\n",
    "    #change the shape of output so that it can do sum process with shotcut\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    with tf.name_scope(\"conv_block_stage\" + str(stage)):\n",
    "\n",
    "        # Retrieve Filters\n",
    "        filter1, filter2, filter3 = filters\n",
    "\n",
    "        # Save the input value\n",
    "        X_shortcut = X_input\n",
    "\n",
    "        # First component of main path\n",
    "        x = tf.layers.conv2d(X_input, filter1,\n",
    "                                 kernel_size=(1, 1),\n",
    "                                 strides=(stride, stride),\n",
    "                                 name=conv_name_base+'2a')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base+'2a', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Second component of main path\n",
    "        x = tf.layers.conv2d(x, filter2, (kernel_size, kernel_size), name=conv_name_base + '2b',padding='same')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2b', training=TRAINING)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Third component of main path\n",
    "        x = tf.layers.conv2d(x, filter3, (1, 1), name=conv_name_base + '2c')\n",
    "        x = tf.layers.batch_normalization(x, axis=3, name=bn_name_base + '2c', training=TRAINING)\n",
    "\n",
    "        # SHORTCUT PATH\n",
    "        X_shortcut = tf.layers.conv2d(X_shortcut, filter3, (1,1),\n",
    "                                      strides=(stride, stride), name=conv_name_base + '1')\n",
    "        X_shortcut = tf.layers.batch_normalization(X_shortcut, axis=3, name=bn_name_base + '1', training=TRAINING)\n",
    "\n",
    "        # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "        X_add_shortcut = tf.add(X_shortcut, x)\n",
    "        add_result = tf.nn.relu(X_add_shortcut)\n",
    "\n",
    "    return add_result\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50_reference(X, classes= 2):\n",
    "#     x = tf.pad(X, tf.constant([[0, 0],[3, 3,], [3, 3], [0, 0]]), \"CONSTANT\")\n",
    "\n",
    "#     assert(x.shape == (x.shape[0], 70, 70, 1))\n",
    "\n",
    "    # stage 1\n",
    "    x = tf.layers.conv2d(X, filters=64, kernel_size=(7, 7), strides=(2, 2), name='conv1')\n",
    "    x = tf.layers.batch_normalization(x, axis=3, name='bn_conv1')\n",
    "    x = tf.nn.relu(x)\n",
    "    # local response normalization\n",
    "    x = tf.nn.lrn(x, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=(3, 3),strides=(2, 2))\n",
    "    \n",
    "\n",
    "\n",
    "    # stage 2\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[64, 64, 256], stage=2, block='a', stride=1)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # stage 3\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[128,128,512],\n",
    "                                            stage=3, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128,128,512], stage=3, block='d')\n",
    "\n",
    "    # stage 4\n",
    "    x = convolutional_block(x, kernel_size=3, filters=[256, 256, 1024], stage=4, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # stage 5\n",
    "    x = convolutional_block(x,kernel_size=3,filters=[512, 512, 2048], stage=5, block='a', stride=2)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    #x = tf.layers.average_pooling2d(x, pool_size=(2, 2), strides=(1,1))\n",
    "    # local response normalization\n",
    "    x = tf.nn.lrn(x, depth_radius=4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=(2, 2), strides=(1,1))\n",
    "\n",
    "    flatten = tf.layers.flatten(x, name='flatten')\n",
    "    # set 1 when testing\n",
    "    keep_prob = 1\n",
    "    # dropout\n",
    "    drop = tf.nn.dropout(flatten, keep_prob)\n",
    "    dense1 = tf.layers.dense(drop, units=50, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(dense1, units=2, activation=tf.nn.softmax)\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(logits, labels, name):\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits \\\n",
    "            (logits=logits, labels=labels, name='xentropy_per_example')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_loss', loss)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_loss', loss)\n",
    "    return loss\n",
    " \n",
    "def trainning(loss, learning_rate):\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_op = optimizer.minimize(loss, global_step= global_step)\n",
    "    return train_op\n",
    " \n",
    "def evaluation(logits, labels, name):\n",
    "    with tf.variable_scope('accuracy') as scope:\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        correct = tf.cast(correct, tf.float16)\n",
    "        accuracy = tf.reduce_mean(correct)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_accuracy', accuracy)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_accuracy', accuracy)\n",
    "    return accuracy\n",
    "\n",
    "# def change_recall(logits,value):\n",
    "#     def re(elem):\n",
    "#         if elem[tf.argmax(elem)]>=value:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "#     predict = tf.map_fn(re, logits)\n",
    "#     return predict\n",
    "\n",
    "def recall_precision(logits, labels, name):\n",
    "#     logits = tf.cast(logits, tf.int64)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    predict = tf.cast(logits,tf.int64)\n",
    "#     predict = tf.arg_max(logits,1)\n",
    "#     predict = tf.cast(change_recall(logits,0.79), tf.int64)\n",
    "    with tf.variable_scope('recall_precision') as scope:\n",
    "        TP = tf.count_nonzero(predict * labels)\n",
    "        TN = tf.count_nonzero((predict - 1) * (labels - 1))\n",
    "        FN = tf.count_nonzero(predict * (labels - 1))\n",
    "        FP = tf.count_nonzero((predict - 1) * labels)\n",
    "        precision = tf.divide(TP, TP + FP)\n",
    "        recall = tf.divide(TP, TP + FN)\n",
    "        precision = tf.cast(precision, dtype=tf.float64)\n",
    "        recall = tf.cast(recall, dtype=tf.float64)\n",
    "        #f1 = 2 * precision * recall / (precision + recall)\n",
    "        #f1 = tf.cast(f1, dtype=tf.float32)\n",
    "        if name=='train':\n",
    "            tf.summary.scalar(scope.name + '/train_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/train_recall', recall)\n",
    "        if name=='valid':\n",
    "            tf.summary.scalar(scope.name + '/valid_precision', precision)\n",
    "            tf.summary.scalar(scope.name + '/valid_recall', recall)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "def get_files(path_pos,path_neg,label_pos,label_neg):\n",
    "    TC = []\n",
    "    label_TC = []\n",
    "    nonTC = []\n",
    "    label_nonTC = []\n",
    "    # data loader\n",
    "    file_dir_TC=path_pos\n",
    "    file_dir_nonTC=path_neg\n",
    "    #len_valTC=len(os.listdir(file_dir_TC))\n",
    "    for file in os.listdir(file_dir_TC):\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_pos:\n",
    "            TC.append(file_dir_TC + file)\n",
    "            label_TC.append(1)\n",
    "    for file in os.listdir(file_dir_nonTC):\n",
    "        name = file.split('_')\n",
    "        if name[0] == label_neg:\n",
    "            nonTC.append(file_dir_nonTC + file)\n",
    "            label_nonTC.append(0)\n",
    "    print(\"There are %d TC\\nThere are %d nonTC\" % (len(TC), len(nonTC)))\n",
    " \n",
    "    # shuffle\n",
    "    image_list = np.hstack((TC, nonTC))\n",
    "    label_list = np.hstack((label_TC, label_nonTC))\n",
    "    temp = np.array([image_list, label_list])\n",
    "    temp = temp.transpose()    \n",
    "    np.random.shuffle(temp)\n",
    " \n",
    "    image_list = list(temp[:, 0])\n",
    "    label_list = list(temp[:, 1])\n",
    "    label_list = [int(i) for i in label_list]\n",
    " \n",
    "    return image_list, label_list\n",
    " \n",
    "# img_list,label_list = get_files(file_dir)\n",
    " \n",
    "# batch\n",
    "def get_batch(image, label, image_W, image_H, batch_size, capacity):   \n",
    "    image = tf.cast(image, tf.string)\n",
    "    label = tf.cast(label, tf.int32)\n",
    " \n",
    "    # queue\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    " \n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    label = input_queue[1]\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=1)\n",
    " \n",
    "    # resize\n",
    "    image = tf.image.resize_images(image, [image_H, image_W], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # image = tf.image.per_image_standardization(image)  \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,  \n",
    "                                              capacity=capacity)\n",
    "  \n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14355 TC\n",
      "There are 434488 nonTC\n",
      "INFO:tensorflow:Restoring parameters from ./train_resnet_lrnaug_balanced/model.ckpt-1564000\n",
      "--------restore done---------\n",
      "---------validation start----------\n",
      "Step 0, valid accuracy = 82.52%, valid recall = 16.67%, valid precision = 2.17%\n",
      "Step 1, valid accuracy = 84.57%, valid recall = 19.23%, valid precision = 2.72%\n",
      "Step 2, valid accuracy = 83.30%, valid recall = 18.42%, valid precision = 3.80%\n",
      "Step 3, valid accuracy = 85.16%, valid recall = 12.20%, valid precision = 2.72%\n",
      "Step 4, valid accuracy = 85.35%, valid recall = 17.14%, valid precision = 3.26%\n",
      "Step 5, valid accuracy = 82.32%, valid recall = 28.57%, valid precision = 3.26%\n",
      "Step 6, valid accuracy = 82.62%, valid recall = 17.50%, valid precision = 3.80%\n",
      "Step 7, valid accuracy = 82.91%, valid recall = 17.14%, valid precision = 3.26%\n",
      "Step 8, valid accuracy = 86.72%, valid recall = 24.39%, valid precision = 5.43%\n",
      "Step 9, valid accuracy = 85.35%, valid recall = 15.00%, valid precision = 3.26%\n",
      "Step 10, valid accuracy = 84.77%, valid recall = 23.53%, valid precision = 4.35%\n",
      "Step 11, valid accuracy = 84.57%, valid recall = 5.56%, valid precision = 1.09%\n",
      "Step 12, valid accuracy = 84.08%, valid recall = 16.13%, valid precision = 2.72%\n",
      "Step 13, valid accuracy = 85.35%, valid recall = 25.00%, valid precision = 3.26%\n",
      "Step 14, valid accuracy = 84.18%, valid recall = 10.71%, valid precision = 1.63%\n",
      "Step 15, valid accuracy = 84.86%, valid recall = 16.13%, valid precision = 2.72%\n",
      "Step 16, valid accuracy = 84.57%, valid recall = 17.39%, valid precision = 2.17%\n",
      "Step 17, valid accuracy = 83.79%, valid recall = 7.14%, valid precision = 1.09%\n",
      "Step 18, valid accuracy = 83.40%, valid recall = 17.86%, valid precision = 2.72%\n",
      "Step 19, valid accuracy = 83.20%, valid recall = 12.00%, valid precision = 1.63%\n",
      "Step 20, valid accuracy = 84.86%, valid recall = 21.05%, valid precision = 4.35%\n",
      "Step 21, valid accuracy = 84.96%, valid recall = 16.22%, valid precision = 3.26%\n",
      "Step 22, valid accuracy = 85.84%, valid recall = 27.50%, valid precision = 5.98%\n",
      "Step 23, valid accuracy = 82.91%, valid recall = 18.18%, valid precision = 3.26%\n",
      "Step 24, valid accuracy = 84.08%, valid recall = 27.03%, valid precision = 5.43%\n",
      "Step 25, valid accuracy = 86.04%, valid recall = 17.39%, valid precision = 2.17%\n",
      "Step 26, valid accuracy = 84.86%, valid recall = 12.20%, valid precision = 2.72%\n",
      "Step 27, valid accuracy = 84.86%, valid recall = 9.52%, valid precision = 2.17%\n",
      "Step 28, valid accuracy = 82.91%, valid recall = 27.78%, valid precision = 5.43%\n",
      "Step 29, valid accuracy = 84.96%, valid recall = 6.25%, valid precision = 1.09%\n",
      "Step 30, valid accuracy = 85.16%, valid recall = 8.57%, valid precision = 1.63%\n",
      "Step 31, valid accuracy = 82.62%, valid recall = 23.08%, valid precision = 3.26%\n",
      "Step 32, valid accuracy = 84.18%, valid recall = 26.09%, valid precision = 3.26%\n",
      "Step 33, valid accuracy = 85.74%, valid recall = 25.00%, valid precision = 4.35%\n",
      "Step 34, valid accuracy = 83.59%, valid recall = 33.33%, valid precision = 7.07%\n",
      "Step 35, valid accuracy = 84.38%, valid recall = 6.45%, valid precision = 1.09%\n",
      "Step 36, valid accuracy = 85.16%, valid recall = 0.00%, valid precision = 0.00%\n",
      "Step 37, valid accuracy = 83.89%, valid recall = 15.38%, valid precision = 3.26%\n",
      "Step 38, valid accuracy = 83.59%, valid recall = 22.22%, valid precision = 4.35%\n",
      "Step 39, valid accuracy = 84.96%, valid recall = 24.44%, valid precision = 5.98%\n",
      "Step 40, valid accuracy = 85.06%, valid recall = 17.39%, valid precision = 2.17%\n",
      "Step 41, valid accuracy = 84.08%, valid recall = 23.53%, valid precision = 4.35%\n",
      "Step 42, valid accuracy = 84.77%, valid recall = 16.67%, valid precision = 3.26%\n",
      "Step 43, valid accuracy = 83.79%, valid recall = 18.18%, valid precision = 4.35%\n",
      "Step 44, valid accuracy = 83.79%, valid recall = 27.27%, valid precision = 4.89%\n",
      "Step 45, valid accuracy = 84.47%, valid recall = 9.52%, valid precision = 1.09%\n",
      "Step 46, valid accuracy = 83.89%, valid recall = 5.26%, valid precision = 1.09%\n",
      "Step 47, valid accuracy = 85.35%, valid recall = 17.39%, valid precision = 2.17%\n",
      "Step 48, valid accuracy = 84.96%, valid recall = 22.22%, valid precision = 4.35%\n",
      "Step 49, valid accuracy = 86.04%, valid recall = 22.22%, valid precision = 4.35%\n",
      "Step 50, valid accuracy = 84.47%, valid recall = 16.67%, valid precision = 2.72%\n",
      "Step 51, valid accuracy = 86.04%, valid recall = 25.64%, valid precision = 5.43%\n",
      "Step 52, valid accuracy = 83.89%, valid recall = 15.15%, valid precision = 2.72%\n",
      "Step 53, valid accuracy = 82.91%, valid recall = 27.27%, valid precision = 4.89%\n",
      "Step 54, valid accuracy = 86.23%, valid recall = 28.57%, valid precision = 5.43%\n",
      "Step 55, valid accuracy = 85.35%, valid recall = 26.47%, valid precision = 4.89%\n",
      "Step 56, valid accuracy = 84.47%, valid recall = 8.33%, valid precision = 1.63%\n",
      "Step 57, valid accuracy = 84.86%, valid recall = 8.70%, valid precision = 1.09%\n",
      "Step 58, valid accuracy = 84.96%, valid recall = 11.90%, valid precision = 2.72%\n",
      "Step 59, valid accuracy = 85.55%, valid recall = 32.35%, valid precision = 5.98%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-18673ec9bb25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mval_acc_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_recall_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_precision_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_precision\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0;31m#val_logits,val_acc_op= sess.run([train_logits, valid_acc])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m#predicts=change_recall(val_logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##validation\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf.device(\"/device:GPU:0\")\n",
    "N_CLASSES = 2 \n",
    "IMG_W = 64  # resize\n",
    "IMG_H = 64\n",
    "BATCH_SIZE = 1024\n",
    "CAPACITY = 20000\n",
    "MAX_STEP = 1000\n",
    "\n",
    "def change_recall(val_logits):\n",
    "    predict=[]\n",
    "    for i in val_logits:\n",
    "#         if i[1]>=0.79:\n",
    "#             predict.append(1)\n",
    "#         else:\n",
    "#             predict.append(0)\n",
    "            predict.append(1)\n",
    "        \n",
    "    predict = np.float32(np.reshape(predict,1024))\n",
    "    return predict\n",
    "\n",
    "file_dir_valTC='/home/ubuntu/data/valTC_cp/'\n",
    "file_dir_valnonTC='/home/ubuntu/data/valnonTC/'\n",
    "\n",
    "valid, valid_label = get_files(file_dir_valTC,file_dir_valnonTC,'valTC','valnonTC')\n",
    "logs_valid_dir='./valid_'\n",
    "\n",
    "valid_batch,valid_label_batch=get_batch(valid,\n",
    "                                valid_label,\n",
    "                                IMG_W,\n",
    "                                IMG_H,\n",
    "                                BATCH_SIZE,\n",
    "                                CAPACITY)\n",
    "\n",
    "#with tf.Graph().as_default():\n",
    "ckpt_path = './train_resnet_lrnaug_balanced/model.ckpt-1564000'\n",
    "\n",
    "# x = tf.placeholder(tf.float32, [BATCH_SIZE,IMG_W,IMG_H,1])\n",
    "# y = tf.placeholder(tf.float32, [BATCH_SIZE])\n",
    "# y = tf.cast(y,tf.int64)\n",
    "pred = tf.placeholder(tf.float32, [1024])\n",
    "train_logits = ResNet50_reference(valid_batch)\n",
    "valid_acc = evaluation(train_logits, valid_label_batch, 'valid')\n",
    "val_recall, val_precision = recall_precision(pred, valid_label_batch, 'valid')\n",
    "#val_recall, val_precision = recall_precision(pred, valid_label_batch, 'valid')\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    #valid_batch,valid_label_batch=sess.run([valid_batch,valid_label_batch])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "#     variables = tf.contrib.framework.get_variables_to_restore()\n",
    "#     variables_to_resotre = [v for v in varialbes if v.name.split('/')[0]!='softmax_linear']\n",
    "\n",
    "    saver.restore(sess,ckpt_path)\n",
    "    print('--------restore done---------')\n",
    "    summary_op = tf.summary.merge_all() \n",
    "\n",
    "    valid_writer = tf.summary.FileWriter(logs_valid_dir, sess.graph)\n",
    "  \n",
    "    print('---------validation start----------')\n",
    "    for step in np.arange(MAX_STEP):  \n",
    "        try:        \n",
    "            for step in np.arange(MAX_STEP):\n",
    "                if coord.should_stop():\n",
    "                        break\n",
    "                val_acc_op, val_recall_op, val_precision_op = sess.run([valid_acc, val_recall, val_precision],feed_dict={pred:predicts})\n",
    "                #val_logits,val_acc_op= sess.run([train_logits, valid_acc])\n",
    "                #predicts=change_recall(val_logits)\n",
    "                #print(np.shape(predicts))\n",
    "                #val_recall_op, val_precision_op = sess.run([val_recall, val_precision],feed_dict={pred:predicts})\n",
    "                #val_acc, cal_recall, val_precision = sess.run([valid__acc, val_recall, val_precision],feed_dict={x:valid_batch,y:valid_label_batch})\n",
    "                #print(val_logits)\n",
    "                print('Step %d, valid accuracy = %.2f%%, valid recall = %.2f%%, valid precision = %.2f%%' %(step, val_acc_op*100.0, val_recall_op*100.0, val_precision_op*100.0))\n",
    "                \n",
    "                        \n",
    "#                 summary_str = sess.run(summary_op)\n",
    "#                 valid_writer.add_summary(summary_str, step)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done validation -- epoch limit reached')\n",
    "\n",
    "        finally:\n",
    "            coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
